{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Analyze speadsheets from Gorilla for ImageNet exp\n",
    "2. Pick representative images for finding explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import glob\n",
    "import os\n",
    "\n",
    "tasks = ['Natural', 'Dog', 'Adversarial_Nat', 'Adversarial_Dog']\n",
    "dataset_path = '/home/dexter/Downloads/Human_experiments/Dataset'\n",
    "ground_truth = dict()\n",
    "\n",
    "# Build the ground truth dictionary \n",
    "\n",
    "CORRECT_BIN1_IMAGES = 'correct_bin1_images/'\n",
    "CORRECT_BIN2_IMAGES = 'correct_bin2_images/'\n",
    "CORRECT_BIN3_IMAGES = 'correct_bin3_images/'\n",
    "WRONG_BIN1_IMAGES = 'wrong_bin1_images/'\n",
    "WRONG_BIN2_IMAGES = 'wrong_bin2_images/'\n",
    "WRONG_BIN3_IMAGES = 'wrong_bin3_images/'\n",
    "bin_images = [CORRECT_BIN1_IMAGES, CORRECT_BIN2_IMAGES, CORRECT_BIN3_IMAGES, WRONG_BIN1_IMAGES, WRONG_BIN2_IMAGES, WRONG_BIN3_IMAGES]\n",
    "easy_bins = [WRONG_BIN1_IMAGES, CORRECT_BIN3_IMAGES]\n",
    "hard_bins = [CORRECT_BIN1_IMAGES, WRONG_BIN3_IMAGES]\n",
    "norm_bins = [CORRECT_BIN2_IMAGES, WRONG_BIN2_IMAGES]\n",
    "correct_bins = [CORRECT_BIN1_IMAGES, CORRECT_BIN2_IMAGES, CORRECT_BIN3_IMAGES]\n",
    "wrong_bins = [WRONG_BIN1_IMAGES, WRONG_BIN2_IMAGES, WRONG_BIN3_IMAGES]\n",
    "\n",
    "\n",
    "for task in tasks:\n",
    "    ground_truth[task] = dict()\n",
    "    task_dataset_path = os.path.join(dataset_path,task)\n",
    "    for CORRECT_BIN_IMAGES in [CORRECT_BIN1_IMAGES, CORRECT_BIN2_IMAGES, CORRECT_BIN3_IMAGES]:\n",
    "        bin_gt_dict = dict()\n",
    "        correct_bin_images_path = os.path.join(task_dataset_path, CORRECT_BIN_IMAGES)\n",
    "        correct_bin_images = [path.split(CORRECT_BIN_IMAGES)[1] for path in glob.glob(correct_bin_images_path + '/*.*')]\n",
    "        for correct_bin_image in correct_bin_images:\n",
    "            bin_gt_dict[correct_bin_image] = 'Yes'\n",
    "        \n",
    "        ground_truth[task][CORRECT_BIN_IMAGES] = bin_gt_dict\n",
    "        \n",
    "    for WRONG_BIN_IMAGES in [WRONG_BIN1_IMAGES, WRONG_BIN2_IMAGES, WRONG_BIN3_IMAGES]:\n",
    "        bin_gt_dict = dict()\n",
    "        wrong_bin_images_path = os.path.join(task_dataset_path, WRONG_BIN_IMAGES)\n",
    "        wrong_bin_images = [path.split(WRONG_BIN_IMAGES)[1] for path in glob.glob(wrong_bin_images_path + '/*.*')]\n",
    "        for wrong_bin_image in wrong_bin_images:\n",
    "            bin_gt_dict[wrong_bin_image] = 'No'\n",
    "        \n",
    "        ground_truth[task][WRONG_BIN_IMAGES] = bin_gt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import operator\n",
    "import os\n",
    "import math\n",
    "import statistics\n",
    "from IPython.core.debugger import Tracer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "# Check if a number is float?\n",
    "def is_float(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Task aliases assigned by Gorilla\n",
    "exp_hierarchy = ['randomiser-tjl7', {'Conf':'counterbalance-lxdj', 'GradCAM': 'counterbalance-yqqs', 'EP': 'counterbalance-jiws', 'SOD': 'counterbalance-eqty', 'NNs': 'counterbalance-xsf1'}]\n",
    "\n",
    "methods = ['Conf', 'GradCAM', 'EP', 'SOD', 'NNs']\n",
    "dataset_path = '/home/dexter/Downloads/Human_experiments/Dataset'\n",
    "\n",
    "# Loop all csv file, each csv file is an explanation method\n",
    "files = []\n",
    "\n",
    "exp = 'Natural'\n",
    "for file in glob.glob('Data/{}/*.*'.format(exp)):\n",
    "    if '.csv' in file:\n",
    "        files.append(file)\n",
    "\n",
    "if exp == 'Natural':\n",
    "    tasks = ['Natural', 'Adversarial_Nat']\n",
    "    threshold = 10\n",
    "else:\n",
    "    tasks = ['Dog', 'Adversarial_Dog']\n",
    "    threshold = 8\n",
    "    \n",
    "csv_file = open('tmp/{}_bad_users.csv'.format(tasks[0]), 'w')\n",
    "final_result = dict()\n",
    "trial_cnt = dict()\n",
    "\n",
    "# Initialize the dictionary for users' responses (answer)\n",
    "for task in tasks:\n",
    "    final_result[task] = dict()\n",
    "    trial_cnt[task] = dict()\n",
    "    for method in methods:\n",
    "        final_result[task][method] = dict()\n",
    "        trial_cnt[task][method] = dict()\n",
    "        for bin_image in bin_images:\n",
    "            final_result[task][method][bin_image] = 0\n",
    "            trial_cnt[task][method][bin_image] = 0\n",
    "\n",
    "# Correct answer dictionary in validation \n",
    "val_correct_dict = dict()\n",
    "# Incorrect answer dictionary in validation \n",
    "val_incorrect_trials_dict = dict()\n",
    "\n",
    "test_correct_trials_dict = dict()\n",
    "test_incorrect_trials_dict = dict()\n",
    "\n",
    "# Numbers of users for methods\n",
    "user_cnt_dict = dict()\n",
    "\n",
    "# Reaction time dictionary \n",
    "users_avg_reaction_time_dict = dict()\n",
    "users_stdev_reaction_time_dict = dict()\n",
    "below_stdev_reaction_time_dict = dict()\n",
    "\n",
    "# Counter-balances for methods\n",
    "counter_balances_dict = dict()\n",
    "\n",
    "# Numbers of good users for methods\n",
    "good_user_cnt_dict = dict()\n",
    "good_user_cnt = 0\n",
    "bad_user_cnt = 0\n",
    "users_reaction_times = []\n",
    "user_dict = dict()\n",
    "\n",
    "for file in files:\n",
    "    reaction_time_correct_cnt_dict = dict()\n",
    "    users_reaction_time = []\n",
    "    users_val_incorrect_trials = []\n",
    "    counter_balances = []\n",
    "    user_cnt = 0\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # Start the spreadsheet for a user\n",
    "        if row['Event Index'] != 'END OF FILE' and int(row['Event Index']) == 1:\n",
    "            user_cnt += 1\n",
    "            reaction_time = 0\n",
    "            reaction_times = []\n",
    "\n",
    "            val_correct = 0\n",
    "            val_incorrect = 0\n",
    "            val_incorrect_trials = []\n",
    "            val_trial_cnt = 0\n",
    "            \n",
    "            test_reaction_time = 0\n",
    "            val_reaction_time = 0\n",
    "\n",
    "            test_trial_answers = {}\n",
    "\n",
    "            task_name = row['Task Name']\n",
    "            \n",
    "            method = task_name.split('_')[1]\n",
    "            if method == 'Confidence':\n",
    "                method = 'Conf'\n",
    "\n",
    "            task = task_name.split('_')[0]\n",
    "            counter_balance = int(row[exp_hierarchy[1][method]])\n",
    "\n",
    "            public_id = row['Participant Public ID']\n",
    "    \n",
    "            if task not in user_dict:\n",
    "                user_dict[task] = dict()\n",
    "                    \n",
    "            if method not in user_dict[task]:\n",
    "                user_dict[task][method] = dict()\n",
    "            if public_id not in user_dict[task][method]:\n",
    "                user_dict[task][method][public_id] = dict()\n",
    "                user_dict[task][method][public_id]['Trials'] = dict()\n",
    "                user_dict[task][method][public_id]['Prior Knowledge'] = dict()\n",
    "                user_dict[task][method][public_id]['Counter balance'] = counter_balance\n",
    "                user_dict[task][method][public_id]['Known'] = 0\n",
    "                user_dict[task][method][public_id]['Unknown'] = 0\n",
    "        \n",
    "        trial_time = row['Reaction Time']\n",
    "            \n",
    "        # Check users' responses in validation\n",
    "        if row['display'] == 'Validation' and row['Screen Name'] == 'Screen 3':\n",
    "            val_trial_cnt += 1\n",
    "            if row['Correct'] == 1:\n",
    "                val_correct += 1\n",
    "            elif row['Incorrect'] == 1:\n",
    "                val_incorrect += 1\n",
    "                val_incorrect_trials.append(val_trial_cnt)\n",
    "            else:\n",
    "                raise ValueError(\"Wrong value!\")\n",
    "                \n",
    "            user_dict[task][method][public_id]['Validation Correct'] = val_correct\n",
    "            user_dict[task][method][public_id]['Validation Incorrect'] = val_incorrect\n",
    "            user_dict[task][method][public_id]['Incorrect Validation Trials'] = val_incorrect_trials\n",
    "            \n",
    "        elif row['display'] == 'Trial' and row['Screen Name'] == 'Screen 1':\n",
    "            prior_knowledge = row['Response']\n",
    "                \n",
    "        # Check users' responses in test\n",
    "        elif row['display'] == 'Trial' and row['Screen Name'] == 'Screen 3':\n",
    "            file_name = row['file_name' + str(counter_balance)]\n",
    "            file_name = (file_name.split('.jpeg')[0]).split('_')[:-1]\n",
    "            file_name = '_'.join(file_name) + '.jpeg'\n",
    "            test_trial_answers[file_name] = row['Response']\n",
    "            \n",
    "            user_dict[task][method][public_id]['Trials'][file_name] = row['Response']\n",
    "            user_dict[task][method][public_id]['Prior Knowledge'][file_name] = prior_knowledge\n",
    "        \n",
    "        # Time from instructions -> the end of Validation\n",
    "        if row['display'] != 'Trial':\n",
    "            if (isinstance(row['Reaction Time'], str) and is_float(row['Reaction Time'])) or (isinstance(row['Reaction Time'], float) and not math.isnan(row['Reaction Time'])):\n",
    "                val_reaction_time += float(row['Reaction Time'])\n",
    "        \n",
    "        # End the spreadsheet for a user\n",
    "        if row['Trial Number'] == 'END TASK':\n",
    "            reaction_time = float(row['Reaction Time'])\n",
    "            \n",
    "            # Validation and Test are combined\n",
    "            user_dict[task][method][public_id]['Validation Reaction Time'] = val_reaction_time\n",
    "            user_dict[task][method][public_id]['Test Reaction Time'] = reaction_time - test_reaction_time\n",
    "            \n",
    "            \n",
    "import pandas as pd  \n",
    "import operator\n",
    "import os\n",
    "import math\n",
    "import statistics\n",
    "from IPython.core.debugger import Tracer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "# Check if a number is float?\n",
    "def is_float(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Task aliases assigned by Gorilla\n",
    "exp_hierarchy = ['randomiser-tjl7', {'Conf':'counterbalance-lxdj', 'GradCAM': 'counterbalance-yqqs', 'EP': 'counterbalance-jiws', 'SOD': 'counterbalance-eqty', 'NNs': 'counterbalance-xsf1'}]\n",
    "\n",
    "if exp == 'Natural':\n",
    "    validation_task_names = ['task-34jo', 'task-hd4d']\n",
    "    test_task_names = ['task-ad35', 'task-v2vz']\n",
    "else:\n",
    "    validation_task_names = ['task-phxr', 'task-w7x5']\n",
    "    test_task_names = ['task-qa38', 'task-wpt2']\n",
    "\n",
    "methods = ['Conf', 'GradCAM', 'EP', 'SOD', 'NNs']\n",
    "dataset_path = '/home/dexter/Downloads/Human_experiments/Dataset'\n",
    "\n",
    "# Loop all csv file, each csv file is an explanation method\n",
    "files = []\n",
    "for file in glob.glob('Data-v2/{}/*.*'.format(exp)):\n",
    "    if '.csv' in file:\n",
    "        files.append(file)\n",
    "        \n",
    "csv_file = open('tmp/{}_bad_users.csv'.format(tasks[0]), 'w')\n",
    "final_result = dict()\n",
    "\n",
    "# Correct answer dictionary in validation \n",
    "val_correct_dict = dict()\n",
    "# Incorrect answer dictionary in validation \n",
    "val_incorrect_trials_dict = dict()\n",
    "\n",
    "test_correct_trials_dict = dict()\n",
    "test_incorrect_trials_dict = dict()\n",
    "\n",
    "# Numbers of users for methods\n",
    "user_cnt_dict = dict()\n",
    "\n",
    "# Reaction time dictionary \n",
    "users_avg_reaction_time_dict = dict()\n",
    "users_stdev_reaction_time_dict = dict()\n",
    "below_stdev_reaction_time_dict = dict()\n",
    "\n",
    "# Counter-balances for methods\n",
    "counter_balances_dict = dict()\n",
    "\n",
    "# Numbers of good users for methods\n",
    "good_user_cnt_dict = dict()\n",
    "good_user_cnt = 0\n",
    "bad_user_cnt = 0\n",
    "users_reaction_times = []\n",
    "# user_dict = dict()\n",
    "\n",
    "for file in files:\n",
    "    reaction_time_correct_cnt_dict = dict()\n",
    "    users_reaction_time = []\n",
    "    users_val_incorrect_trials = []\n",
    "    counter_balances = []\n",
    "    user_cnt = 0\n",
    "    df = pd.read_csv(file)\n",
    "#     reaction_time = (df['Reaction Time'].sum()/1000)/60 # in minutes\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # Start the spreadsheet for a user\n",
    "        if row['Event Index'] != 'END OF FILE' and int(row['Event Index']) == 1:\n",
    "#             print('-------- STATISTICS FOR USER NUMBER {} --------'.format(user_cnt))\n",
    "            reaction_time = 0\n",
    "            reaction_times = []\n",
    "\n",
    "            val_correct = 0\n",
    "            val_incorrect = 0\n",
    "            val_incorrect_trials = []\n",
    "            val_trial_cnt = 0\n",
    "            \n",
    "            prior_knowledge_dict = dict() # To process mismatched answers in prior knowledge test\n",
    "\n",
    "            test_trial_answers = {}\n",
    "\n",
    "            task_name = row['Task Name']\n",
    "#             print(task_name)\n",
    "            method = task_name.split('_')[1]\n",
    "            if method == 'Confidence':\n",
    "                method = 'Conf'\n",
    "\n",
    "            task = task_name.split('_')[0]\n",
    "            counter_balance = int(row[exp_hierarchy[1][method]])\n",
    "# #             print(task_name, method, counter_balance)\n",
    "#             counter_balances.append(counter_balance)\n",
    "\n",
    "            public_id = row['Participant Public ID']\n",
    "    \n",
    "            if task not in user_dict:\n",
    "                user_dict[task] = dict()\n",
    "                    \n",
    "            if method not in user_dict[task]:\n",
    "                user_dict[task][method] = dict()\n",
    "            if public_id not in user_dict[task][method]:\n",
    "                user_dict[task][method][public_id] = dict()\n",
    "                user_dict[task][method][public_id]['Trials'] = dict()\n",
    "                user_dict[task][method][public_id]['Counter balance'] = counter_balance\n",
    "                user_dict[task][method][public_id]['Prior Knowledge'] = dict()\n",
    "                user_dict[task][method][public_id]['Known'] = 0\n",
    "                user_dict[task][method][public_id]['Unknown'] = 0\n",
    "            \n",
    "        # Check users' responses in validation\n",
    "        if row['display'] == 'Validation' and row['Screen Name'] == 'Screen 3':\n",
    "            val_trial_cnt += 1\n",
    "            if row['Correct'] == 1:\n",
    "                val_correct += 1\n",
    "            elif row['Incorrect'] == 1:\n",
    "                val_incorrect += 1\n",
    "                val_incorrect_trials.append(val_trial_cnt)\n",
    "            else:\n",
    "                raise ValueError(\"Wrong value!\")\n",
    "                \n",
    "            user_dict[task][method][public_id]['Validation Correct'] = val_correct\n",
    "            user_dict[task][method][public_id]['Validation Incorrect'] = val_incorrect\n",
    "            user_dict[task][method][public_id]['Incorrect Validation Trials'] = val_incorrect_trials\n",
    "            \n",
    "        elif row['display'] == 'Trial' and row['Screen Name'] == 'Screen 1':\n",
    "            prior_knowledge = row['Response']\n",
    "                \n",
    "        # Check users' responses in test\n",
    "        elif row['display'] == 'Trial' and row['Screen Name'] == 'Screen 3':\n",
    "            file_name = row['file_name' + str(counter_balance)]\n",
    "            file_name = (file_name.split('.jpeg')[0]).split('_')[:-1]\n",
    "            file_name = '_'.join(file_name) + '.jpeg'\n",
    "            test_trial_answers[file_name] = row['Response']\n",
    "            \n",
    "            user_dict[task][method][public_id]['Trials'][file_name] = row['Response']\n",
    "            \n",
    "            # file_name[:9] is the predicted ID\n",
    "            # If someones said unknown to a class, the same classes in the test should be also unknown\n",
    "            if file_name[:9] not in prior_knowledge_dict:\n",
    "                prior_knowledge_dict[file_name[:9]] = prior_knowledge\n",
    "\n",
    "            user_dict[task][method][public_id]['Prior Knowledge'][file_name] = prior_knowledge_dict[file_name[:9]]\n",
    "                \n",
    "                \n",
    "        # End the spreadsheet for a user\n",
    "        if row['Trial Number'] == 'END TASK':\n",
    "            reaction_time = float(row['Reaction Time'])\n",
    "            \n",
    "            # Validation and Test are separated\n",
    "            if row['Tree Node Key'] in validation_task_names:\n",
    "                user_dict[task][method][public_id]['Validation Reaction Time'] = reaction_time\n",
    "            else:\n",
    "                user_dict[task][method][public_id]['Test Reaction Time'] = reaction_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User_dict\n",
    "- Natural\n",
    "    - Methods\n",
    "        - User_IDs\n",
    "            - ['Trials', '\n",
    "            - Counter balance', \n",
    "            - 'Validation Correct', ' # The number of correct validation trials\n",
    "            - Validation Incorrect', ' # The number of incorrect validation trials\n",
    "            - Incorrect Validation Trials', ' # The IDs of incorrect validation trials\n",
    "            - Validation Reaction Time', '#  # Time from instructions -> the end of Validation\n",
    "            - Test Reaction Time', ' # Time taken for 30 test trials\n",
    "            - Quality']) # This user qualified the validation or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_correct_trials_dict = dict()\n",
    "\n",
    "# Initialize the dictionary for users' responses (answer)\n",
    "for task in tasks:\n",
    "    final_result[task] = dict()\n",
    "    trial_cnt[task] = dict()\n",
    "    for method in methods:\n",
    "        final_result[task][method] = dict()\n",
    "        trial_cnt[task][method] = dict()\n",
    "        for bin_image in bin_images:\n",
    "            final_result[task][method][bin_image] = 0\n",
    "            trial_cnt[task][method][bin_image] = 0\n",
    "\n",
    "task = exp\n",
    "for method in methods:\n",
    "    good_user_cnt = 0\n",
    "    hacking_user_cnt = 0\n",
    "    correct_cnt_list = []\n",
    "    \n",
    "    if method not in test_correct_trials_dict:\n",
    "        test_correct_trials_dict[method] = dict()\n",
    "    \n",
    "    for user_id in user_dict[task][method].keys():\n",
    "        user_dict[task][method][user_id]['Known'] = 0\n",
    "        user_dict[task][method][user_id]['Unknown'] = 0\n",
    "    \n",
    "        if user_dict[task][method][user_id]['Validation Correct'] >= threshold:\n",
    "            good_user_cnt += 1\n",
    "            user_dict[task][method][user_id]['Quality'] = 'Good'\n",
    "        else:\n",
    "            user_dict[task][method][user_id]['Quality'] = 'Bad'\n",
    "            continue\n",
    "        \n",
    "        trials = user_dict[task][method][user_id]['Trials']\n",
    "        \n",
    "        # Initialize: The correct times a trial gets {trial_name: times}\n",
    "        for trial_key in trials.keys():\n",
    "            if trial_key not in test_correct_trials_dict[method]:\n",
    "                test_correct_trials_dict[method][trial_key] = dict()\n",
    "                test_correct_trials_dict[method][trial_key]['Count'] = 0\n",
    "                test_correct_trials_dict[method][trial_key]['Counter balance'] = list()\n",
    "            test_correct_trials_dict[method][trial_key]['Counter balance'].append(user_dict[task][method][user_id]['Counter balance'])\n",
    "                \n",
    "        if task == 'Natural':\n",
    "            task_list = ['Natural', 'Adversarial_Nat']\n",
    "        elif task == 'Dog':\n",
    "            task_list = ['Dog', 'Adversarial_Dog']\n",
    "            \n",
    "        # Record the number of correct answers of a user for every bin\n",
    "        for sub_task in task_list: \n",
    "            user_dict[task][method][user_id][sub_task] = dict()\n",
    "            exp_gt = ground_truth[sub_task]\n",
    "\n",
    "            for CORRECT_BIN_IMAGES in [CORRECT_BIN1_IMAGES, CORRECT_BIN2_IMAGES, CORRECT_BIN3_IMAGES]:\n",
    "                shared_items = {k: exp_gt[CORRECT_BIN_IMAGES][k] for k in exp_gt[CORRECT_BIN_IMAGES] if k in trials and exp_gt[CORRECT_BIN_IMAGES][k] == trials[k]}\n",
    "                user_dict[task][method][user_id][sub_task][CORRECT_BIN_IMAGES] = len(shared_items)\n",
    "                \n",
    "                # Get: The correct times a trial gets {trial_name: times}\n",
    "                for key in shared_items.keys():\n",
    "                    test_correct_trials_dict[method][key]['Bin'] = CORRECT_BIN_IMAGES\n",
    "                    test_correct_trials_dict[method][key]['Count'] += 1\n",
    "                    test_correct_trials_dict[method][key]['Task'] = sub_task\n",
    "                    if user_dict[task][method][user_id]['Prior Knowledge'][key] == 'Yes':\n",
    "                        user_dict[task][method][user_id]['Known'] += 1\n",
    "                    else:\n",
    "                        user_dict[task][method][user_id]['Unknown'] += 1\n",
    "                \n",
    "                # Get: The prediction of AI on this image\n",
    "                for key in exp_gt[CORRECT_BIN_IMAGES].keys():\n",
    "                    if key in test_correct_trials_dict[method]:\n",
    "                        test_correct_trials_dict[method][key]['Prediction'] = 'Correct'\n",
    "                \n",
    "                trial_cnt[sub_task][method][CORRECT_BIN_IMAGES] += len(set.intersection(set(ground_truth[sub_task][CORRECT_BIN_IMAGES].keys()), set(trials.keys())))\n",
    "                \n",
    "            for WRONG_BIN_IMAGES in [WRONG_BIN1_IMAGES, WRONG_BIN2_IMAGES, WRONG_BIN3_IMAGES]:\n",
    "                shared_items = {k: exp_gt[WRONG_BIN_IMAGES][k] for k in exp_gt[WRONG_BIN_IMAGES] if k in trials and exp_gt[WRONG_BIN_IMAGES][k] == trials[k]}\n",
    "                user_dict[task][method][user_id][sub_task][WRONG_BIN_IMAGES] = len(shared_items)\n",
    "                \n",
    "                # Get: The correct times a trial gets {trial_name: times}                    \n",
    "                for key in shared_items.keys():\n",
    "                    test_correct_trials_dict[method][key]['Bin'] = WRONG_BIN_IMAGES\n",
    "                    test_correct_trials_dict[method][key]['Count'] += 1\n",
    "                    test_correct_trials_dict[method][key]['Task'] = sub_task\n",
    "                    if user_dict[task][method][user_id]['Prior Knowledge'][key] == 'Yes':\n",
    "                        user_dict[task][method][user_id]['Known'] += 1\n",
    "                    else:\n",
    "                        user_dict[task][method][user_id]['Unknown'] += 1\n",
    "                    \n",
    "                # Get: The prediction of AI on this image\n",
    "                for key in exp_gt[WRONG_BIN_IMAGES].keys():\n",
    "                    if key in test_correct_trials_dict[method]:\n",
    "                        test_correct_trials_dict[method][key]['Prediction'] = 'Wrong'\n",
    "\n",
    "                trial_cnt[sub_task][method][WRONG_BIN_IMAGES] += len(set.intersection(set(ground_truth[sub_task][WRONG_BIN_IMAGES].keys()), set(trials.keys())))\n",
    "\n",
    "        correct_cnt = sum(user_dict[exp][method][user_id][tasks[0]].values()) + sum(user_dict[exp][method][user_id][tasks[1]].values())\n",
    "        correct_cnt_list.append((correct_cnt/30)*100)\n",
    "        \n",
    "    print('Method = {} std_dev = {}'.format(method, statistics.stdev(correct_cnt_list)))\n",
    "    print('mean = {}'.format(statistics.mean(correct_cnt_list)))\n",
    "    print('{}/{} good users of {}'.format(good_user_cnt, len(user_dict[task][method]), method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "reader = csv.reader(open('csv_files/definition.csv'))\n",
    "definition_dict = dict()\n",
    "for row in reader:\n",
    "    key = row[0][:9]\n",
    "    definition = row[0][12:]\n",
    "    definition_dict[key] = definition\n",
    "# Added for loading ImageNet classes\n",
    "def load_imagenet_id_map():\n",
    "    \"\"\"\n",
    "    Load ImageNet ID dictionary.\n",
    "    return;\n",
    "    \"\"\"\n",
    "\n",
    "    input_f = open(\"input_txt_files/synset_words.txt\")\n",
    "    label_map = {}\n",
    "    for line in input_f:\n",
    "        parts = line.strip().split(\" \")\n",
    "        (num, label) = (parts[0], ' '.join(parts[1:]))\n",
    "        label_map[num] = label\n",
    "\n",
    "    input_f.close()\n",
    "    return label_map\n",
    "id_map = load_imagenet_id_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "model = models.resnet34(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Pre-process the image and convert into a tensor\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def make_dir(path):\n",
    "    if os.path.isdir(path) == False:\n",
    "        os.mkdir(path)\n",
    "\n",
    "# Added for loading ImageNet classes\n",
    "def load_imagenet_label_map():\n",
    "    \"\"\"\n",
    "    Load ImageNet label dictionary.\n",
    "    return:\n",
    "    \"\"\"\n",
    "\n",
    "    input_f = open(\"input_txt_files/imagenet_classes.txt\")\n",
    "    label_map = {}\n",
    "    for line in input_f:\n",
    "        parts = line.strip().split(\": \")\n",
    "        (num, label) = (int(parts[0]), parts[1].replace('\"', \"\"))\n",
    "        label_map[num] = label\n",
    "\n",
    "    input_f.close()\n",
    "    return label_map\n",
    "\n",
    "\n",
    "# Added for loading ImageNet classes\n",
    "def load_imagenet_id_map():\n",
    "    \"\"\"\n",
    "    Load ImageNet ID dictionary.\n",
    "    return;\n",
    "    \"\"\"\n",
    "\n",
    "    input_f = open(\"input_txt_files/synset_words.txt\")\n",
    "    label_map = {}\n",
    "    for line in input_f:\n",
    "        parts = line.strip().split(\" \")\n",
    "        (num, label) = (parts[0], ' '.join(parts[1:]))\n",
    "        label_map[num] = label\n",
    "\n",
    "    input_f.close()\n",
    "    return label_map\n",
    "\n",
    "def load_imagenet_validation_gt():\n",
    "    count = 0\n",
    "    input_f = open(\"input_txt_files/ILSVRC2012_validation_ground_truth.txt\")\n",
    "    gt_dict = {}\n",
    "    while True:\n",
    "        count += 1\n",
    "        \n",
    "        # Get the next line\n",
    "        line = input_f.readline()\n",
    "        \n",
    "        # if line is empty, EOL is reached\n",
    "        if not line:\n",
    "            break\n",
    "        gt_dict [count] = int(line.strip())\n",
    "\n",
    "    input_f.close()\n",
    "    return gt_dict\n",
    "\n",
    "def convert_imagenet_label_to_id(label_map, key_list, val_list, prediction_class):\n",
    "    \"\"\"\n",
    "    Convert imagenet label to ID: for example - 245 -> \"French bulldog\" -> n02108915\n",
    "    :param label_map:\n",
    "    :param key_list:\n",
    "    :param val_list:\n",
    "    :param prediction_class:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    class_to_label = label_map[prediction_class]\n",
    "    prediction_id = key_list[val_list.index(class_to_label)]\n",
    "    return prediction_id\n",
    "\n",
    "gt_dict = load_imagenet_validation_gt()\n",
    "id_map = load_imagenet_id_map()\n",
    "label_map = load_imagenet_label_map()\n",
    "\n",
    "key_list = list(id_map.keys())\n",
    "val_list = list(id_map.values())\n",
    "\n",
    "print(key_list[200])\n",
    "\n",
    "def convert_imagenet_id_to_label(key_list, class_id):\n",
    "    \"\"\"\n",
    "    Convert imagenet label to ID: for example - n02108915 -> \"French bulldog\" -> 245\n",
    "    :param label_map:\n",
    "    :param key_list:\n",
    "    :param val_list:\n",
    "    :param prediction_class:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return key_list.index(str(class_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1\n",
    "acc_dict = dict()\n",
    "print('Q1: Are heatmaps more effective than 3-NNs in improving AI+human accuracy in classifying random ImageNet images?')\n",
    "for task in tasks:\n",
    "    acc_dict[task] = dict()\n",
    "    print(\"In {} images:\".format(task.split('_')[0]))\n",
    "    accuracies = []\n",
    "    best_acc = 0\n",
    "    best_method = ''\n",
    "    for method in methods:\n",
    "        correct_cnt = 0\n",
    "        known_crt_cnt = 0\n",
    "        unknown_crt_cnt = 0\n",
    "        for user_id in user_dict[exp][method].keys():\n",
    "            if user_dict[exp][method][user_id]['Quality'] == 'Good':\n",
    "                correct_cnt += sum(user_dict[exp][method][user_id][task].values())\n",
    "                known_crt_cnt += user_dict[exp][method][user_id]['Known']\n",
    "                unknown_crt_cnt += user_dict[exp][method][user_id]['Unknown']\n",
    "                \n",
    "#                 print(sum(user_dict[exp][method][user_id][task].values()), user_dict[exp][method][user_id]['Known'], user_dict[exp][method][user_id]['Unknown'])\n",
    "\n",
    "        total_cnt = sum(trial_cnt[task][method].values())\n",
    "#         print(\"Correct count: {} on Total count: {}\".format(correct_cnt, total_cnt))\n",
    "        if total_cnt:\n",
    "            acc = correct_cnt*100/total_cnt\n",
    "            acc_dict[task][method] = round(acc,2) # limit to 2 decimals\n",
    "            accuracies.append(acc)\n",
    "            print(\"Task: {} | Method: {} | Accuracy: {:.2f}%\".format(task, method, correct_cnt*100/total_cnt))\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_method = method\n",
    "                \n",
    "        print(total_cnt)\n",
    "    print(\"Answer: The best method is {} with an accuracy of {:.2f}%\".format(best_method, best_acc))\n",
    "    print(\"Answer: Mean accuracy is {:.2f}%\".format(sum(accuracies)/len(accuracies)))\n",
    "    \n",
    "print(acc_dict)\n",
    "\n",
    "known_crt_acc = []\n",
    "unknown_crt_acc = []\n",
    "for method in methods:\n",
    "    correct_cnt = 0\n",
    "    known_crt_cnt = 0\n",
    "    unknown_crt_cnt = 0\n",
    "    total_known_cnt = 0\n",
    "    total_unknown_cnt = 0\n",
    "    for user_id in user_dict[exp][method].keys():\n",
    "        if user_dict[exp][method][user_id]['Quality'] == 'Good':\n",
    "            # print(user_dict[exp][method][user_id]['Known'])\n",
    "            known_crt_cnt += user_dict[exp][method][user_id]['Known']\n",
    "            unknown_crt_cnt += user_dict[exp][method][user_id]['Unknown']\n",
    "            total_known_cnt += sum(value == 'Yes' for value in user_dict[exp][method][user_id]['Prior Knowledge'].values())\n",
    "            total_unknown_cnt += sum(value == 'No' for value in user_dict[exp][method][user_id]['Prior Knowledge'].values())\n",
    "    print(known_crt_cnt, total_known_cnt, unknown_crt_cnt, total_unknown_cnt)\n",
    "    known_crt_acc.append(known_crt_cnt*100/total_known_cnt)\n",
    "    unknown_crt_acc.append(unknown_crt_cnt*100/total_unknown_cnt)\n",
    "    print(\"On Known images: Method: {} | Accuracy: {:.2f}%\".format(method, known_crt_cnt*100/total_known_cnt))\n",
    "    print(\"On Unknown images: Method: {} | Accuracy: {:.2f}%\".format(method, unknown_crt_cnt*100/total_unknown_cnt))\n",
    "                           \n",
    "print(\"Answer: Known Mean accuracy is {:.2f}%\".format(sum(known_crt_acc)/len(known_crt_acc)))\n",
    "print(\"Answer: Unnown Mean accuracy is {:.2f}%\".format(sum(unknown_crt_acc)/len(unknown_crt_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2\n",
    "print('Q2: Are heatmaps more effective than 3-NNs in improving AI+human accuracy in classifying natural ImageNet images that are harder or easier to AIs?')\n",
    "print('-------------- RESULT OF EASY IMAGES --------------')\n",
    "for task in tasks:\n",
    "    print(\"In {} images:\".format(task.split('_')[0]))\n",
    "    accuracies = []\n",
    "    best_acc = 0\n",
    "    best_method = ''\n",
    "    for method in methods:\n",
    "        correct_cnt = 0\n",
    "        total_cnt = 0\n",
    "        for user_id in user_dict[exp][method].keys():\n",
    "            if user_dict[exp][method][user_id]['Quality'] == 'Good':\n",
    "                for easy_bin in easy_bins:\n",
    "#                 for easy_bin in [CORRECT_BIN3_IMAGES]:\n",
    "                    correct_cnt += user_dict[exp][method][user_id][task][easy_bin]\n",
    "        for easy_bin in easy_bins:            \n",
    "            total_cnt += trial_cnt[task][method][easy_bin]\n",
    "#             total_cnt = trial_cnt[task][method][CORRECT_BIN3_IMAGES]\n",
    "        print(correct_cnt, total_cnt)\n",
    "                    \n",
    "#         print(\"Correct count: {} on Total count: {}\".format(correct_cnt, total_cnt))\n",
    "        if total_cnt:\n",
    "            acc = correct_cnt*100/total_cnt\n",
    "            accuracies.append(acc)\n",
    "            print(\"Task: {} | Method: {} | Accuracy: {:.2f}%\".format(task, method, acc))\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_method = method\n",
    "#     print(\"Answer: The best method is {} with an accuracy of {:.2f}%\".format(best_method, best_acc))\n",
    "#     print(\"Answer: Mean accuracy is {:.2f}%\".format(sum(accuracies)/len(accuracies)))\n",
    "    \n",
    "print('-------------- RESULT OF HARD IMAGES --------------')\n",
    "for task in tasks:\n",
    "    print(\"In {} images:\".format(task.split('_')[0]))\n",
    "    accuracies = []\n",
    "    best_acc = 0\n",
    "    best_method = ''\n",
    "    for method in methods:\n",
    "        correct_cnt = 0\n",
    "        total_cnt = 0\n",
    "        for user_id in user_dict[exp][method].keys():\n",
    "            if user_dict[exp][method][user_id]['Quality'] == 'Good':\n",
    "                for hard_bin in hard_bins:\n",
    "#                 for hard_bin in [CORRECT_BIN1_IMAGES]:\n",
    "                    correct_cnt += user_dict[exp][method][user_id][task][hard_bin]\n",
    "        for hard_bin in hard_bins:            \n",
    "            total_cnt += trial_cnt[task][method][hard_bin]\n",
    "#             total_cnt = trial_cnt[task][method][CORRECT_BIN1_IMAGES]\n",
    "                    \n",
    "#         print(\"Correct count: {} on Total count: {}\".format(correct_cnt, total_cnt))\n",
    "        if total_cnt:\n",
    "            acc = correct_cnt*100/total_cnt\n",
    "            accuracies.append(acc)\n",
    "            print(\"Task: {} | Method: {} | Accuracy: {:.2f}%\".format(task, method, acc))\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_method = method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3\n",
    "print('Q3: Are heatmaps more effective than 3-NNs in improving AI+human accuracy when AIs are not sure i.e. 50/50?')\n",
    "print('-------------- RESULT OF NORMAL IMAGES --------------')\n",
    "for task in tasks:\n",
    "    print(\"In {} images:\".format(task.split('_')[0]))\n",
    "    accuracies = []\n",
    "    best_acc = 0\n",
    "    best_method = ''\n",
    "    for method in methods:\n",
    "        correct_cnt = 0\n",
    "        total_cnt = 0\n",
    "        for user_id in user_dict[exp][method].keys():\n",
    "            if user_dict[exp][method][user_id]['Quality'] == 'Good':\n",
    "                for norm_bin in norm_bins:\n",
    "#                 for norm_bin in [CORRECT_BIN2_IMAGES]:\n",
    "                    correct_cnt += user_dict[exp][method][user_id][task][norm_bin]\n",
    "        for norm_bin in norm_bins:            \n",
    "            total_cnt += trial_cnt[task][method][norm_bin]\n",
    "\n",
    "        if total_cnt:\n",
    "            acc = correct_cnt*100/total_cnt\n",
    "            accuracies.append(acc)\n",
    "            print(\"Task: {} | Method: {} | Accuracy: {:.2f}%\".format(task, method, acc))\n",
    "            if  acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_method = method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Q4\n",
    "print('Q4: Which methods help humans the most when AI is correct or wrong?')\n",
    "correct_dict = dict()\n",
    "print('-------------- RESULT OF CORRECT IMAGES --------------')\n",
    "for task in tasks:\n",
    "    print(\"In {} images:\".format(task.split('_')[0]))\n",
    "    best_acc = 0\n",
    "    best_method = ''\n",
    "    for method in methods:\n",
    "        correct_cnt = 0\n",
    "        total_cnt = 0\n",
    "        for user_id in user_dict[exp][method].keys():\n",
    "            if user_dict[exp][method][user_id]['Quality'] == 'Good':\n",
    "                for CORRECT_BIN_IMAGES in [CORRECT_BIN1_IMAGES, CORRECT_BIN2_IMAGES, CORRECT_BIN3_IMAGES]:\n",
    "                    correct_cnt += user_dict[exp][method][user_id][task][CORRECT_BIN_IMAGES]\n",
    "        for CORRECT_BIN_IMAGES in [CORRECT_BIN1_IMAGES, CORRECT_BIN2_IMAGES, CORRECT_BIN3_IMAGES]:     \n",
    "            total_cnt += trial_cnt[task][method][CORRECT_BIN_IMAGES]\n",
    "                    \n",
    "        print(\"Correct count: {} on Total count: {}\".format(correct_cnt, total_cnt))\n",
    "        if task == exp:\n",
    "            correct_dict[method] = (correct_cnt, total_cnt)\n",
    "        if total_cnt:\n",
    "            print(\"Task: {} | Method: {} | Accuracy: {:.2f}%\".format(task, method, correct_cnt*100/total_cnt))\n",
    "            if correct_cnt*100/total_cnt > best_acc:\n",
    "                best_acc = correct_cnt*100/total_cnt\n",
    "                best_method = method\n",
    "    \n",
    "    print(\"Answer: The best method is {} with an accuracy of {:.2f}%\".format(best_method, best_acc))\n",
    "    \n",
    "wrong_dict = dict()\n",
    "print('-------------- RESULT OF WRONG IMAGES --------------')\n",
    "for task in tasks:\n",
    "    print(\"In {} images:\".format(task.split('_')[0]))\n",
    "    best_acc = 0\n",
    "    best_method = ''\n",
    "    for method in methods:\n",
    "        correct_cnt = 0\n",
    "        total_cnt = 0\n",
    "        for user_id in user_dict[exp][method].keys():\n",
    "            if user_dict[exp][method][user_id]['Quality'] == 'Good':\n",
    "                for WRONG_BIN_IMAGES in [WRONG_BIN1_IMAGES, WRONG_BIN2_IMAGES, WRONG_BIN3_IMAGES]:\n",
    "                    correct_cnt += user_dict[exp][method][user_id][task][WRONG_BIN_IMAGES]\n",
    "        for WRONG_BIN_IMAGES in [WRONG_BIN1_IMAGES, WRONG_BIN2_IMAGES, WRONG_BIN3_IMAGES]:   \n",
    "            total_cnt += trial_cnt[task][method][WRONG_BIN_IMAGES]\n",
    "                    \n",
    "        print(\"Correct count: {} on Total count: {}\".format(correct_cnt, total_cnt))\n",
    "        if task == exp:\n",
    "            wrong_dict[method] = (correct_cnt, total_cnt)\n",
    "        if total_cnt:\n",
    "            print(\"Task: {} | Method: {} | Accuracy: {:.2f}%\".format(task, method, correct_cnt*100/total_cnt))\n",
    "            if correct_cnt*100/total_cnt > best_acc:\n",
    "                best_acc = correct_cnt*100/total_cnt\n",
    "                best_method = method\n",
    "    \n",
    "    print(\"Answer: The best method is {} with an accuracy of {:.2f}%\".format(best_method, best_acc))\n",
    "    \n",
    "for method in correct_dict.keys():\n",
    "    print((correct_dict[method][1] - correct_dict[method][0] + wrong_dict[method][0]))\n",
    "    print(correct_dict[method][1] + wrong_dict[method][1])\n",
    "    reject_ratio = (correct_dict[method][1] - correct_dict[method][0] + wrong_dict[method][0])*100/(correct_dict[method][1] + wrong_dict[method][1])\n",
    "    print(\"Method: {} Rejection rate {:.2f}% Acceptance rate {:.2f}%\".format(method, reject_ratio, 100 -reject_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q?\n",
    "print('Q?: Test time vs accuracy?')\n",
    "time_vs_accuracy = dict()\n",
    "time_vs_accuracy[exp] = dict()\n",
    "for method in methods:\n",
    "    time_vs_accuracy[exp][method] = dict()\n",
    "    for user_id in user_dict[exp][method].keys():\n",
    "        correct_cnt = 0\n",
    "        if user_dict[exp][method][user_id]['Quality'] == 'Good':\n",
    "            test_time = user_dict[exp][method][user_id]['Test Reaction Time']/60/1000\n",
    "            for task in tasks:\n",
    "                correct_cnt += sum(user_dict[exp][method][user_id][task].values())\n",
    "            time_vs_accuracy[exp][method][test_time] = correct_cnt\n",
    "            \n",
    "    time_vs_accuracy[exp][method] = {k: time_vs_accuracy[exp][method][k] for k in sorted(time_vs_accuracy[exp][method])}\n",
    "    \n",
    "    print(np.corrcoef(list(time_vs_accuracy[exp][method].keys()), list(time_vs_accuracy[exp][method].values())))\n",
    "    ax = plt.figure().gca()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.scatter(time_vs_accuracy[exp][method].keys(), time_vs_accuracy[exp][method].values())\n",
    "    plt.title('Task: {} | Method: {}'.format(exp, method))\n",
    "    plt.ylabel('Correct answers')\n",
    "    plt.xlabel('Minutes')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "for method in methods:\n",
    "    print(method)\n",
    "    print(sum(time_vs_accuracy[exp][method].keys())/len(time_vs_accuracy[exp][method].keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'serif',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "\n",
    "import csv\n",
    "for test_method in ['GradCAM', 'EP']:\n",
    "    for test_metric in ['WSL', 'Pointing_Game', 'IoU']:\n",
    "        human_acc_dict = dict()\n",
    "        for trial_key, value in test_correct_trials_dict[test_method].items():\n",
    "            # 48 is the len of un-attacked images. e.g. n03857828_ILSVRC2012_val_00009423_n03857828.jpeg\n",
    "            if len(trial_key) <= 48:\n",
    "                key = trial_key.split('.jpeg')[0]\n",
    "                if exp not in human_acc_dict:\n",
    "                    human_acc_dict[exp] = dict()\n",
    "                if value['Prediction'] not in human_acc_dict[exp]:\n",
    "                    human_acc_dict[exp][value['Prediction']] = dict()\n",
    "\n",
    "                # Normalize correct count on an image on the number of users saw the image\n",
    "        #         human_acc_dict['Natural'][value['Prediction']][key] = value['Count']\n",
    "                # Filter out images only seen by one person\n",
    "                if len(test_correct_trials_dict[test_method][trial_key]['Counter balance']) > 1:\n",
    "                    human_acc_dict[exp][value['Prediction']][key] = value['Count']/len(test_correct_trials_dict[test_method][trial_key]['Counter balance'])\n",
    "        human_acc_dict[exp]['Correct'] = {k: human_acc_dict[exp]['Correct'][k] for k in sorted(human_acc_dict[exp]['Correct'])}     \n",
    "        \n",
    "        \n",
    "        if exp == 'Natural':\n",
    "            metric_csv = '/home/dexter/Downloads/A-journey-into-Convolutional-Neural-Network-visualization-/saliency_maps/{}_{}_resnet34_{}_metrics.csv'.format(test_metric, test_method, 'ImageNet')\n",
    "        else:\n",
    "            metric_csv = '/home/dexter/Downloads/A-journey-into-Convolutional-Neural-Network-visualization-/saliency_maps/{}_{}_resnet34_{}_metrics.csv'.format(test_metric, test_method, exp)\n",
    "\n",
    "        reader = csv.reader(open(metric_csv))\n",
    "        definition_dict = dict()\n",
    "        proxy_acc_dict = dict()\n",
    "        for row in reader:\n",
    "            key = row[0].split('.npy')[0]\n",
    "            if test_metric == 'IoU':\n",
    "                proxy_acc_dict[key] = float(row[1])\n",
    "            elif test_metric == 'WSL': \n",
    "                if float(row[1]) > 0:\n",
    "                    value = 0\n",
    "                else:\n",
    "                    value = 1\n",
    "                proxy_acc_dict[key] = value\n",
    "            elif test_metric == 'Pointing_Game': \n",
    "                if float(row[1]) > 0:\n",
    "                    value = 1\n",
    "                else:\n",
    "                    value = 0\n",
    "                proxy_acc_dict[key] = value\n",
    "\n",
    "\n",
    "        proxy_acc_dict = {k: proxy_acc_dict[k] for k in sorted(proxy_acc_dict)}\n",
    "\n",
    "        human_acc = []\n",
    "        proxy_acc = []\n",
    "        for key, value in human_acc_dict[exp]['Correct'].items():\n",
    "            human_acc.append(value)\n",
    "            proxy_acc.append(proxy_acc_dict[key])\n",
    "        print('The number users for {} is {}'.format(test_method, len(human_acc)))\n",
    "        print('The correlation b/w proxy metric and human accuracy is:')\n",
    "        pearson_matrix = np.corrcoef(proxy_acc, human_acc)\n",
    "        print(pearson_matrix)\n",
    "        pearson_coeff = pearson_matrix[0][1]\n",
    "        print(pearson_coeff)\n",
    "        \n",
    "        from scipy.stats import gaussian_kde\n",
    "        \n",
    "        density = dict()\n",
    "        for idx, _ in enumerate(proxy_acc):\n",
    "            if (proxy_acc[idx], human_acc[idx]) in density:\n",
    "                density[(proxy_acc[idx], human_acc[idx])] += 1\n",
    "            else:\n",
    "                density[(proxy_acc[idx], human_acc[idx])] = 1\n",
    "        \n",
    "        z = []\n",
    "        for idx, _ in enumerate(proxy_acc):\n",
    "            z.append(density[(proxy_acc[idx], human_acc[idx])])\n",
    "        z_arr = np.array(z)\n",
    "            \n",
    "        x = proxy_acc\n",
    "        y = human_acc\n",
    "\n",
    "        # Calculate the point density\n",
    "        xy = np.vstack([x,y])\n",
    "#         z = gaussian_kde(xy)(xy)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls='--', c='grey')\n",
    "        cm = plt.cm.jet\n",
    "        sc = ax.scatter(x, y, c=z_arr, s=100, vmin=z_arr.min(), vmax=z_arr.max(), edgecolor='', cmap=cm)\n",
    "        \n",
    "        plt.title('Pearson correlation: {}'.format(round(pearson_coeff,2)))\n",
    "        plt.ylabel('Human accuracy')\n",
    "        plt.xlabel(test_metric)\n",
    "        plt.colorbar(sc, label='Number of images per point')\n",
    "        plt.savefig('correlation_figures/{}_{}_{}.pdf'.format(exp, test_method, test_metric),dpi=300, format='pdf', bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_hist = dict()\n",
    "for IoU in proxy_acc:\n",
    "    interval = int(IoU*10)\n",
    "    if interval in acc_hist:\n",
    "        acc_hist[interval] += 1\n",
    "    else:\n",
    "        acc_hist[interval] = 1\n",
    "acc_hist = {k: acc_hist[k] for k in sorted(acc_hist)}\n",
    "ax = plt.figure().gca()\n",
    "# ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.hist(proxy_acc, density=False, bins=10, ec='black')  # density=False would make counts\n",
    "plt.title(test_method)\n",
    "plt.ylabel('Numb. of images')\n",
    "plt.xlabel(test_metric)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain: Why NNs performed better than other heatmaps in Adversarial ImageNet\n",
    "target_method = 'NNs'\n",
    "candidates = []\n",
    "cnt = 0\n",
    "cnt_balance = 0\n",
    "for key in test_correct_trials_dict[target_method].keys():\n",
    "    # Only care wrong images | If the image were recognized by all users | And the image should be Natural not Adversarial\n",
    "    if test_correct_trials_dict[target_method][key]['Prediction'] == 'Wrong' \\\n",
    "    and test_correct_trials_dict[target_method][key]['Count'] == len(test_correct_trials_dict[target_method][key]['Counter balance']) \\\n",
    "    and test_correct_trials_dict[target_method][key]['Task'] == 'Adversarial_Nat' \\\n",
    "    and len(test_correct_trials_dict[target_method][key]['Counter balance']) > cnt_balance:\n",
    "#         print(test_correct_trials_dict['SOD'][key])\n",
    "        cnt += 1\n",
    "        candidates.append(key)\n",
    "print(cnt)\n",
    "\n",
    "representatives = []\n",
    "for candidate in candidates:\n",
    "    flag = True\n",
    "    flag_cnt = 0\n",
    "    for method in ['GradCAM', 'SOD']:\n",
    "        if candidate in test_correct_trials_dict[method] and len(test_correct_trials_dict[method][candidate]['Counter balance']) > cnt_balance:\n",
    "#             print(test_correct_trials_dict[method][candidate]['Count'], len(test_correct_trials_dict[method][candidate]['Counter balance']))\n",
    "            if test_correct_trials_dict[method][candidate]['Count'] < len(test_correct_trials_dict[method][candidate]['Counter balance']):\n",
    "#             if test_correct_trials_dict[method][candidate]['Count'] < 2:\n",
    "                flag_cnt += 1\n",
    "#                 break\n",
    "\n",
    "    if flag_cnt == 2:\n",
    "        representatives.append(candidate)\n",
    "print(len(representatives))\n",
    "# print(representatives)\n",
    "# print(candidates)\n",
    "\n",
    "data_path = '/home/dexter/Downloads/Human_experiments/Visualization/{}/'.format('Adversarial_Nat')\n",
    "dst_path = 'Finding_explanations/NNs_adversarial_imagenet'\n",
    "dst_aggregate_path = 'Finding_explanations/NNs_adversarial_imagenet_aggregate/'\n",
    "\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "# Now we have the representatives, we copy the explanations (GradCAM, EP, ....) on the representatives to a folder\n",
    "for representative in representatives:\n",
    "    cmd = 'montage'\n",
    "    representative_idx = representative.split('.jpeg')[0]\n",
    "    for method in ['GradCAM', 'SOD', 'NNs']:\n",
    "        method_path = method\n",
    "        if method == 'SOD':\n",
    "            method_path = 'PoolNet'\n",
    "        method_path = os.path.join(data_path, method_path)\n",
    "        vis_paths = glob.glob(method_path + '/*.*')\n",
    "        for vis_path in vis_paths:\n",
    "            if representative_idx in vis_path:\n",
    "                src = vis_path\n",
    "                dst = os.path.join(dst_path, representative_idx + '_' + method + '.jpeg')\n",
    "                cmd += ' ' + dst\n",
    "                copyfile(src, dst)\n",
    "                if method == 'Conf':\n",
    "                    size = '600x600'\n",
    "                elif method in ['GradCAM', 'EP', 'SOD']:\n",
    "                    size = '1200x600'\n",
    "                else:\n",
    "                    size = '2400x600'\n",
    "                if method == 'NNs':\n",
    "                    method = '3-NNs'\n",
    "                os.system('convert {} -resize {}\\! -pointsize 28 -gravity North -background White -splice 0x32 -annotate +0+4 \"{}\" {}'.format(dst, size, method, dst))\n",
    "    aggregate_path = os.path.join(dst_aggregate_path, representative)\n",
    "    \n",
    "    gt_label = representative[34:43]\n",
    "    print(representative)\n",
    "    sample_path = '/home/dexter/Downloads/A-journey-into-Convolutional-Neural-Network-visualization-/sample_images'\n",
    "    predicted_sample_path = os.path.join(sample_path, gt_label + '.jpeg')\n",
    "    print(gt_label)\n",
    "    textual_label = id_map.get(gt_label).split(',')[0]\n",
    "    textual_label = textual_label[0].lower() + textual_label[1:]\n",
    "    definition = '{}: {}'.format(textual_label, definition_dict[gt_label])\n",
    "    print(definition)\n",
    "    os.system('convert  -font Times-New-Roman {} -pointsize 12 -gravity North -background White -splice 0x32 -annotate +0+4 \"{}\" {}'.format(predicted_sample_path, definition, representative))\n",
    "    \n",
    "    cmd += ' ' + representative\n",
    "    print(gt_label)\n",
    "    \n",
    "    cmd += ' -tile 1x4 -geometry 2400x600+0+0 ' +  aggregate_path\n",
    "    os.system(cmd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What made NNs so useful compared to heatmaps in Hard, Natural ImageNet?\n",
    "# Hard set = correct_bin1_images/ + wrong_bin3_images/\n",
    "target_method = 'NNs'\n",
    "candidates = []\n",
    "cnt = 0\n",
    "correct = 0\n",
    "wrong = 0\n",
    "cnt_balance = 0\n",
    "for key in test_correct_trials_dict[target_method].keys():\n",
    "    # If the image were corrected by all users | The number of users > cnt_balance | The image is hard\n",
    "    if test_correct_trials_dict[target_method][key]['Count'] == len(test_correct_trials_dict[target_method][key]['Counter balance']) \\\n",
    "    and test_correct_trials_dict[target_method][key]['Task'] == 'Natural' \\\n",
    "    and len(test_correct_trials_dict[target_method][key]['Counter balance']) > cnt_balance \\\n",
    "    and test_correct_trials_dict[target_method][key]['Bin'] in hard_bins:\n",
    "#         print(test_correct_trials_dict['SOD'][key])\n",
    "        cnt += 1\n",
    "#         print(test_correct_trials_dict[target_method][key]['Bin'])\n",
    "        \n",
    "        candidates.append(key)\n",
    "print(cnt)\n",
    "\n",
    "representatives = []\n",
    "for candidate in candidates:\n",
    "    flag = True\n",
    "    flag_cnt = 0\n",
    "    for method in ['GradCAM', 'EP', 'SOD']:\n",
    "        if candidate in test_correct_trials_dict[method] and len(test_correct_trials_dict[method][candidate]['Counter balance']) > cnt_balance:\n",
    "#             print(test_correct_trials_dict[method][candidate]['Count'], len(test_correct_trials_dict[method][candidate]['Counter balance']))\n",
    "            if test_correct_trials_dict[method][candidate]['Count'] < len(test_correct_trials_dict[method][candidate]['Counter balance']):\n",
    "#             if test_correct_trials_dict[method][candidate]['Count'] < 2:\n",
    "                flag_cnt += 1\n",
    "#                 break\n",
    "\n",
    "    if flag_cnt >= 2:\n",
    "        if test_correct_trials_dict[target_method][candidate]['Prediction'] == 'Correct':\n",
    "            correct +=1\n",
    "        else:\n",
    "            wrong +=1\n",
    "        representatives.append(candidate)\n",
    "print(len(representatives))\n",
    "print(correct, wrong)\n",
    "print(representatives)\n",
    "# print(candidates)\n",
    "\n",
    "data_path = '/home/dexter/Downloads/Human_experiments/Visualization/{}/'.format('Natural')\n",
    "dst_path = 'Finding_explanations/NNs_hard_imagenet'\n",
    "dst_aggregate_path = 'Finding_explanations/NNs_hard_imagenet_aggregate/'\n",
    "\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "# Now we have the representatives, we copy the explanations (GradCAM, EP, ....) on the representatives to a folder\n",
    "for representative in representatives:\n",
    "    if test_correct_trials_dict[target_method][representative]['Prediction'] == 'Correct':\n",
    "        input_image_folder = '/home/dexter/Downloads/Human_experiments/Dataset/Natural/correct_bin1_images'\n",
    "    else:\n",
    "        input_image_folder = '/home/dexter/Downloads/Human_experiments/Dataset/Natural/wrong_bin3_images'\n",
    "    \n",
    "    input_image_path = os.path.join(input_image_folder, representative)\n",
    "    print(input_image_path)\n",
    "    cmd = 'montage'\n",
    "    representative_idx = representative.split('.jpeg')[0]\n",
    "    for method in ['SOD', 'GradCAM', 'EP', 'NNs']:\n",
    "        method_path = method\n",
    "        if method == 'SOD':\n",
    "            method_path = 'PoolNet'\n",
    "        method_path = os.path.join(data_path, method_path)\n",
    "        vis_paths = glob.glob(method_path + '/*.*')\n",
    "        for vis_path in vis_paths:\n",
    "            if representative_idx in vis_path:\n",
    "                src = vis_path\n",
    "                dst = os.path.join(dst_path, representative_idx + '_' + method + '.jpeg')\n",
    "                cmd += ' ' + dst\n",
    "                copyfile(src, dst)\n",
    "                if method == 'Conf':\n",
    "                    size = '600x600'\n",
    "                elif method in ['GradCAM', 'EP', 'SOD']:\n",
    "                    size = '1200x600'\n",
    "                else:\n",
    "                    size = '2400x600'\n",
    "                    \n",
    "                if method == 'NNs':\n",
    "                    method = '3-NNs'\n",
    "                os.system('convert {} -resize {}\\! -pointsize 28 -gravity North -background White -splice 0x32 -annotate +0+4 \"{}\" {}'.format(dst, size, method, dst))\n",
    "    aggregate_path = os.path.join(dst_aggregate_path, representative)\n",
    "    \n",
    "    # Get top-k predictions\n",
    "    img = Image.open(input_image_path)\n",
    "    x = transform(img).unsqueeze(0)\n",
    "    out = model(x)\n",
    "    p = torch.nn.functional.softmax(out, dim=1)\n",
    "    score, index = torch.topk(p, 5)\n",
    "#     Tracer()()\n",
    "    input_category_id = index[0][0].item()\n",
    "    predicted_confidence = score[0][0].item()\n",
    "    \n",
    "    predicted_labels = []\n",
    "    predicted_confidences = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        input_prediction_id = convert_imagenet_label_to_id(label_map, key_list, val_list, index[0][i].item())\n",
    "        predicted_label = id_map.get(input_prediction_id).split(',')[0]\n",
    "        predicted_label = predicted_label[0].lower() + predicted_label[1:]\n",
    "        predicted_labels.append(predicted_label)\n",
    "        predicted_confidences.append(score[0][i].item())\n",
    "        \n",
    "#     plt.rcdefaults()\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    y_pos = np.arange(len(predicted_labels))\n",
    "\n",
    "    ax.barh(predicted_labels, predicted_confidences, align='center')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(predicted_labels)\n",
    "    ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax.set_title('Top-5 predictions with confidence')\n",
    "\n",
    "    plt.savefig('tmp/top5.jpeg',dpi=600, format='jpeg', bbox_inches='tight')\n",
    "    \n",
    "    # Get definitions and sample images\n",
    "    gt_label = representative[34:43]\n",
    "    print(representative)\n",
    "    sample_path = '/home/dexter/Downloads/A-journey-into-Convolutional-Neural-Network-visualization-/sample_images'\n",
    "    predicted_sample_path = os.path.join(sample_path, gt_label + '.jpeg')\n",
    "    print(gt_label)\n",
    "    textual_label = id_map.get(gt_label).split(',')[0]\n",
    "    textual_label = textual_label[0].lower() + textual_label[1:]\n",
    "    definition = '{}: {}'.format(textual_label, definition_dict[gt_label])\n",
    "    print(definition)\n",
    "    os.system('convert  -font Times-New-Roman {} -pointsize 12 -gravity North -background White -splice 0x32 -annotate +0+4 \"{}\" {}'.format(predicted_sample_path, definition, representative))\n",
    "    \n",
    "    cmd += ' ' + representative\n",
    "    cmd += ' top5.jpeg'\n",
    "    print(gt_label)\n",
    "    print(cmd)\n",
    "    \n",
    "    cmd += ' -tile 2x3 -geometry 4800x2400+0+0 ' +  aggregate_path\n",
    "    os.system(cmd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_correct_trials_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-362c99a6dfe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcnt_balance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_correct_trials_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_method\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# If the image were corrected by all users | The number of users > cnt_balance | The image is hard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_correct_trials_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_method\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_correct_trials_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_method\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Counter balance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_correct_trials_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# What made NNs so useful compared to heatmaps in Wrong easy, Natural ImageNet?\n",
    "# Hard set = correct_bin1_images/ + wrong_bin3_images/\n",
    "target_method = 'NNs'\n",
    "candidates = []\n",
    "cnt = 0\n",
    "correct = 0\n",
    "wrong = 0\n",
    "cnt_balance = 0\n",
    "for key in test_correct_trials_dict[target_method].keys():\n",
    "    # If the image were corrected by all users | The number of users > cnt_balance | The image is hard\n",
    "    if test_correct_trials_dict[target_method][key]['Count'] == len(test_correct_trials_dict[target_method][key]['Counter balance']) \\\n",
    "    and test_correct_trials_dict[target_method][key]['Task'] == 'Natural' \\\n",
    "    and len(test_correct_trials_dict[target_method][key]['Counter balance']) > cnt_balance \\\n",
    "    and test_correct_trials_dict[target_method][key]['Bin'] in easy_bins:\n",
    "#         print(test_correct_trials_dict['SOD'][key])\n",
    "        cnt += 1\n",
    "#         print(test_correct_trials_dict[target_method][key]['Bin'])\n",
    "        \n",
    "        candidates.append(key)\n",
    "print(cnt)\n",
    "\n",
    "representatives = []\n",
    "for candidate in candidates:\n",
    "    flag = True\n",
    "    flag_cnt = 0\n",
    "    for method in ['GradCAM', 'SOD']:\n",
    "        if candidate in test_correct_trials_dict[method] and len(test_correct_trials_dict[method][candidate]['Counter balance']) > cnt_balance:\n",
    "#             print(test_correct_trials_dict[method][candidate]['Count'], len(test_correct_trials_dict[method][candidate]['Counter balance']))\n",
    "            if test_correct_trials_dict[method][candidate]['Count'] < len(test_correct_trials_dict[method][candidate]['Counter balance']):\n",
    "            # if test_correct_trials_dict[method][candidate]['Count'] == 0:\n",
    "                flag_cnt += 1\n",
    "#                 break\n",
    "\n",
    "    if flag_cnt >= 2:\n",
    "        if test_correct_trials_dict[target_method][candidate]['Prediction'] == 'Correct':\n",
    "            correct +=1\n",
    "        else:\n",
    "            wrong +=1\n",
    "        representatives.append(candidate)\n",
    "print(len(representatives))\n",
    "print(correct, wrong)\n",
    "print(representatives)\n",
    "# print(candidates)\n",
    "\n",
    "data_path = '/home/dexter/Downloads/Human_experiments/Visualization/{}/'.format('Natural')\n",
    "dst_path = 'Finding_explanations/NNs_easy_imagenet'\n",
    "dst_aggregate_path = 'Finding_explanations/NNs_easy_imagenet_aggregate/'\n",
    "\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "# Now we have the representatives, we copy the explanations (GradCAM, EP, ....) on the representatives to a folder\n",
    "for representative in representatives:\n",
    "    if test_correct_trials_dict[target_method][representative]['Prediction'] == 'Correct':\n",
    "        input_image_folder = '/home/dexter/Downloads/Human_experiments/Dataset/Natural/correct_bin3_images'\n",
    "    else:\n",
    "        input_image_folder = '/home/dexter/Downloads/Human_experiments/Dataset/Natural/wrong_bin1_images'\n",
    "    \n",
    "    input_image_path = os.path.join(input_image_folder, representative)\n",
    "    print(input_image_path)\n",
    "    cmd = 'montage'\n",
    "    representative_idx = representative.split('.jpeg')[0]\n",
    "    for method in ['SOD', 'GradCAM', 'EP', 'NNs']:\n",
    "        method_path = method\n",
    "        if method == 'SOD':\n",
    "            method_path = 'PoolNet'\n",
    "        method_path = os.path.join(data_path, method_path)\n",
    "        vis_paths = glob.glob(method_path + '/*.*')\n",
    "        for vis_path in vis_paths:\n",
    "            if representative_idx in vis_path:\n",
    "                src = vis_path\n",
    "                dst = os.path.join(dst_path, representative_idx + '_' + method + '.jpeg')\n",
    "                cmd += ' ' + dst\n",
    "                copyfile(src, dst)\n",
    "                if method == 'Conf':\n",
    "                    size = '600x600'\n",
    "                elif method in ['GradCAM', 'EP', 'SOD']:\n",
    "                    size = '1200x600'\n",
    "                else:\n",
    "                    size = '2400x600'\n",
    "                    \n",
    "                if method == 'NNs':\n",
    "                    method = '3-NNs'\n",
    "                os.system('convert {} -resize {}\\! -pointsize 28 -gravity North -background White -splice 0x32 -annotate +0+4 \"{}\" {}'.format(dst, size, method, dst))\n",
    "    aggregate_path = os.path.join(dst_aggregate_path, representative)\n",
    "    \n",
    "    # Get top-k predictions\n",
    "    img = Image.open(input_image_path)\n",
    "    x = transform(img).unsqueeze(0)\n",
    "    out = model(x)\n",
    "    p = torch.nn.functional.softmax(out, dim=1)\n",
    "    score, index = torch.topk(p, 5)\n",
    "#     Tracer()()\n",
    "    input_category_id = index[0][0].item()\n",
    "    predicted_confidence = score[0][0].item()\n",
    "    \n",
    "    predicted_labels = []\n",
    "    predicted_confidences = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        input_prediction_id = convert_imagenet_label_to_id(label_map, key_list, val_list, index[0][i].item())\n",
    "        predicted_label = id_map.get(input_prediction_id).split(',')[0]\n",
    "        predicted_label = predicted_label[0].lower() + predicted_label[1:]\n",
    "        predicted_labels.append(predicted_label)\n",
    "        predicted_confidences.append(score[0][i].item())\n",
    "        \n",
    "#     plt.rcdefaults()\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    y_pos = np.arange(len(predicted_labels))\n",
    "\n",
    "    ax.barh(predicted_labels, predicted_confidences, align='center')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(predicted_labels)\n",
    "    ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax.set_title('Top-5 predictions with confidence')\n",
    "\n",
    "    plt.savefig('tmp/top5.jpeg',dpi=600, format='jpeg', bbox_inches='tight')\n",
    "    \n",
    "    # Get definitions and sample images\n",
    "    gt_label = representative[34:43]\n",
    "    print(representative)\n",
    "    sample_path = '/home/dexter/Downloads/A-journey-into-Convolutional-Neural-Network-visualization-/sample_images'\n",
    "    predicted_sample_path = os.path.join(sample_path, gt_label + '.jpeg')\n",
    "    print(gt_label)\n",
    "    textual_label = id_map.get(gt_label).split(',')[0]\n",
    "    textual_label = textual_label[0].lower() + textual_label[1:]\n",
    "    definition = '{}: {}'.format(textual_label, definition_dict[gt_label])\n",
    "    print(definition)\n",
    "    os.system('convert  -font Times-New-Roman {} -pointsize 12 -gravity North -background White -splice 0x32 -annotate +0+4 \"{}\" {}'.format(predicted_sample_path, definition, representative))\n",
    "    \n",
    "    cmd += ' ' + representative\n",
    "    cmd += ' top5.jpeg'\n",
    "    print(gt_label)\n",
    "    print(cmd)\n",
    "    \n",
    "    cmd += ' -tile 2x3 -geometry 4800x2400+0+0 ' +  aggregate_path\n",
    "    os.system(cmd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_correct_trials_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-528c4d21b56a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcnt_balance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrepresentatives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_correct_trials_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_method\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# print(test_correct_trials_dict[target_method][key])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# If the image were corrected by all users | The number of users > cnt_balance | The image is normal(medium)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_correct_trials_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# Why 3-NN does not work in Medium Natural ImageNet?\n",
    "target_method = 'NNs'\n",
    "candidates = []\n",
    "cnt = 0\n",
    "correct = 0\n",
    "wrong = 0\n",
    "cnt_balance = -1\n",
    "representatives = []\n",
    "for key in test_correct_trials_dict[target_method].keys():\n",
    "    # print(test_correct_trials_dict[target_method][key])\n",
    "    # If the image were corrected by all users | The number of users > cnt_balance | The image is normal(medium)\n",
    "    # = len(test_correct_trials_dict[target_method][key]['Counter balance']) \\\n",
    "    # if test_correct_trials_dict[target_method][key]['Count'] > 0 \\\n",
    "    if test_correct_trials_dict[target_method][key]['Count'] < len(test_correct_trials_dict[target_method][key]['Counter balance']):\n",
    "    # == 0:\n",
    "        # print(test_correct_trials_dict[target_method][key])\n",
    "        representatives.append(key)\n",
    "        \n",
    "# print(candidates)\n",
    "\n",
    "data_path = '/home/dexter/Downloads/Human_experiments/Visualization/{}/'.format('Natural')\n",
    "dst_path = 'Finding_explanations/GradCAM_norm_imagenet'\n",
    "dst_aggregate_path = 'Finding_explanations/GradCAM_norm_imagenet_aggregate/'\n",
    "\n",
    "\n",
    "from shutil import copyfile\n",
    "import os\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "# Now we have the representatives, we copy the explanations (GradCAM, EP, ....) on the representatives to a folder\n",
    "for representative in representatives:\n",
    "    if test_correct_trials_dict[target_method][representative]['Prediction'] == 'Correct':\n",
    "        input_image_folder = '/home/dexter/Downloads/Human_experiments/Dataset/Natural/correct_bin2_images'\n",
    "    else:\n",
    "        input_image_folder = '/home/dexter/Downloads/Human_experiments/Dataset/Natural/wrong_bin2_images'\n",
    "        \n",
    "    input_image_path = os.path.join(input_image_folder, representative)\n",
    "    \n",
    "    if not os.path.exists(input_image_path):\n",
    "        continue\n",
    "    cnt += 1\n",
    "    if test_correct_trials_dict[target_method][representative]['Prediction'] == 'Correct':\n",
    "        correct +=1\n",
    "    else:\n",
    "        wrong +=1\n",
    "    print(input_image_path)\n",
    "    cmd = 'montage'\n",
    "    representative_idx = representative.split('.jpeg')[0]\n",
    "    for method in ['GradCAM', 'EP', 'NNs']:\n",
    "        method_path = method\n",
    "        if method == 'SOD':\n",
    "            method_path = 'PoolNet'\n",
    "        method_path = os.path.join(data_path, method_path)\n",
    "        vis_paths = glob.glob(method_path + '/*.*')\n",
    "        for vis_path in vis_paths:\n",
    "            if representative_idx in vis_path:\n",
    "                src = vis_path\n",
    "                dst = os.path.join(dst_path, representative_idx + '_' + method + '.jpeg')\n",
    "                cmd += ' ' + dst\n",
    "                copyfile(src, dst)\n",
    "                if method == 'Conf':\n",
    "                    size = '600x600'\n",
    "                elif method in ['GradCAM', 'EP', 'SOD']:\n",
    "                    size = '1200x600'\n",
    "                else:\n",
    "                    size = '2400x600'\n",
    "                    \n",
    "                if method == 'NNs':\n",
    "                    method = '3-NNs'\n",
    "                os.system('convert {} -resize {}\\! -pointsize 28 -gravity North -background White -splice 0x32 -annotate +0+4 \"{}\" {}'.format(dst, size, method, dst))\n",
    "    aggregate_path = os.path.join(dst_aggregate_path, representative)\n",
    "    \n",
    "    # Get top-k predictions\n",
    "    img = Image.open(input_image_path)\n",
    "    x = transform(img).unsqueeze(0)\n",
    "    out = model(x)\n",
    "    p = torch.nn.functional.softmax(out, dim=1)\n",
    "    score, index = torch.topk(p, 5)\n",
    "#     Tracer()()\n",
    "    input_category_id = index[0][0].item()\n",
    "    predicted_confidence = score[0][0].item()\n",
    "    \n",
    "    predicted_labels = []\n",
    "    predicted_confidences = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        input_prediction_id = convert_imagenet_label_to_id(label_map, key_list, val_list, index[0][i].item())\n",
    "        predicted_label = id_map.get(input_prediction_id).split(',')[0]\n",
    "        predicted_label = predicted_label[0].lower() + predicted_label[1:]\n",
    "        predicted_labels.append(predicted_label)\n",
    "        predicted_confidences.append(score[0][i].item())\n",
    "        \n",
    "#     plt.rcdefaults()\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    y_pos = np.arange(len(predicted_labels))\n",
    "\n",
    "    ax.barh(predicted_labels, predicted_confidences, align='center')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(predicted_labels)\n",
    "    ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax.set_title('Top-5 predictions with confidence')\n",
    "\n",
    "    plt.savefig('tmp/top5.jpeg',dpi=600, format='jpeg', bbox_inches='tight')\n",
    "    \n",
    "    # Get definitions and sample images\n",
    "    gt_label = representative[34:43]\n",
    "    print(representative)\n",
    "    sample_path = '/home/dexter/Downloads/A-journey-into-Convolutional-Neural-Network-visualization-/sample_images'\n",
    "    predicted_sample_path = os.path.join(sample_path, gt_label + '.jpeg')\n",
    "    print(gt_label)\n",
    "    textual_label = id_map.get(gt_label).split(',')[0]\n",
    "    textual_label = textual_label[0].lower() + textual_label[1:]\n",
    "    definition = '{}: {}'.format(textual_label, definition_dict[gt_label])\n",
    "    print(definition)\n",
    "    os.system('convert  -font Times-New-Roman {} -pointsize 12 -gravity North -background White -splice 0x32 -annotate +0+4 \"{}\" {}'.format(predicted_sample_path, definition, representative))\n",
    "    \n",
    "    cmd += ' ' + representative\n",
    "    cmd += ' top5.jpeg'\n",
    "    print(gt_label)\n",
    "    print(cmd)\n",
    "    \n",
    "    cmd += ' -tile 2x3 -geometry 4800x2400+0+0 ' +  aggregate_path\n",
    "    os.system(cmd)\n",
    "print(cnt, correct, wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why GradCAM is better than EP and SOD in correct ImageNet images\n",
    "target_method = 'GradCAM'\n",
    "candidates = []\n",
    "cnt = 0\n",
    "correct = 0\n",
    "wrong = 0\n",
    "cnt_balance = 0\n",
    "for key in test_correct_trials_dict[target_method].keys():\n",
    "    # Only care wrong images | If the image were recognized by all users | And the image should be Natural not Adversarial\n",
    "    if test_correct_trials_dict[target_method][key]['Count'] == len(test_correct_trials_dict[target_method][key]['Counter balance']) \\\n",
    "    and test_correct_trials_dict[target_method][key]['Task'] == 'Natural' \\\n",
    "    and len(test_correct_trials_dict[target_method][key]['Counter balance']) > cnt_balance \\\n",
    "    and test_correct_trials_dict[target_method][key]['Bin'] in [CORRECT_BIN2_IMAGES]:\n",
    "#         print(test_correct_trials_dict['SOD'][key])\n",
    "        cnt += 1\n",
    "#         print(test_correct_trials_dict[target_method][key]['Bin'])\n",
    "        \n",
    "        candidates.append(key)\n",
    "print(cnt)\n",
    "\n",
    "representatives = []\n",
    "for candidate in candidates:\n",
    "    flag = True\n",
    "    flag_cnt = 0\n",
    "    for method in ['EP']:\n",
    "        if candidate in test_correct_trials_dict[method] and len(test_correct_trials_dict[method][candidate]['Counter balance']) > cnt_balance:\n",
    "#             print(test_correct_trials_dict[method][candidate]['Count'], len(test_correct_trials_dict[method][candidate]['Counter balance']))\n",
    "            if test_correct_trials_dict[method][candidate]['Count'] < len(test_correct_trials_dict[method][candidate]['Counter balance']):\n",
    "#             if test_correct_trials_dict[method][candidate]['Count'] < 2:\n",
    "                flag_cnt += 1\n",
    "#                 break\n",
    "\n",
    "    if flag_cnt == 1:\n",
    "        if test_correct_trials_dict[target_method][candidate]['Prediction'] == 'Correct':\n",
    "            correct +=1\n",
    "        else:\n",
    "            wrong +=1\n",
    "        representatives.append(candidate)\n",
    "print(len(representatives))\n",
    "print(correct, wrong)\n",
    "print(representatives)\n",
    "# print(candidates)\n",
    "\n",
    "data_path = '/home/dexter/Downloads/Human_experiments/Visualization/{}/'.format('Natural')\n",
    "dst_path = 'Finding_explanations/GradCAM_correct_imagenet'\n",
    "dst_aggregate_path = 'Finding_explanations/GradCAM_correct_imagenet_aggregate/'\n",
    "\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "# Now we have the representatives, we copy the explanations (GradCAM, EP, ....) on the representatives to a folder\n",
    "for representative in representatives:\n",
    "#     if test_correct_trials_dict[target_method][representative]['Prediction'] == 'Correct':\n",
    "#         correct +=1\n",
    "# #         continue\n",
    "#     else:\n",
    "#         wrong +=1\n",
    "    cmd = 'montage'\n",
    "    representative_idx = representative.split('.jpeg')[0]\n",
    "    for method in ['GradCAM', 'EP']:\n",
    "        method_path = method\n",
    "        if method == 'SOD':\n",
    "            method_path = 'PoolNet'\n",
    "        method_path = os.path.join(data_path, method_path)\n",
    "        vis_paths = glob.glob(method_path + '/*.*')\n",
    "        for vis_path in vis_paths:\n",
    "            if representative_idx in vis_path:\n",
    "                src = vis_path\n",
    "                dst = os.path.join(dst_path, representative_idx + '_' + method + '.jpeg')\n",
    "                cmd += ' ' + dst\n",
    "                copyfile(src, dst)\n",
    "                if method == 'Conf':\n",
    "                    size = '600x600'\n",
    "                elif method in ['GradCAM', 'EP', 'SOD']:\n",
    "                    size = '1200x600'\n",
    "                else:\n",
    "                    size = '2400x600'\n",
    "                if method == 'NNs':\n",
    "                    method = '3-NNs'\n",
    "                os.system('convert {} -resize {}\\! -pointsize 28 -gravity North -background White -splice 0x32 -annotate +0+4 \"{}\" {}'.format(dst, size, method, dst))\n",
    "    aggregate_path = os.path.join(dst_aggregate_path, representative)\n",
    "    cmd += ' -tile 1x2 -geometry 2400x600+0+0 ' +  aggregate_path\n",
    "    os.system(cmd)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
