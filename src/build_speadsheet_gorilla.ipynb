{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build spreadsheets to upload to Gorilla.sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "reader = csv.reader(open('csv_files/definition.csv'))\n",
    "definition_dict = dict()\n",
    "for row in reader:\n",
    "    key = row[0][:9]\n",
    "    definition = row[0][12:]\n",
    "    definition_dict[key] = definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "sample_images_path = '/home/dexter/Downloads/A-journey-into-Convolutional-Neural-Network-visualization-/sample_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added for loading ImageNet classes\n",
    "def load_imagenet_id_map():\n",
    "    \"\"\"\n",
    "    Load ImageNet ID dictionary.\n",
    "    return;\n",
    "    \"\"\"\n",
    "\n",
    "    input_f = open(\"input_txt_files/synset_words.txt\")\n",
    "    label_map = {}\n",
    "    for line in input_f:\n",
    "        parts = line.strip().split(\" \")\n",
    "        (num, label) = (parts[0], ' '.join(parts[1:]))\n",
    "        label_map[num] = label\n",
    "\n",
    "    input_f.close()\n",
    "    return label_map\n",
    "id_map = load_imagenet_id_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:Dog | Method: NNs\n",
      "450\n",
      "No\n",
      "Yes\n",
      "Yes\n",
      "Yes\n",
      "No\n",
      "No\n",
      "Yes\n",
      "No\n",
      "No\n",
      "Yes\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "task = 'Dog'\n",
    "adv_task = 'Adversarial_Dog'\n",
    "# methods = ['Conf', 'GradCAM', 'EP', 'NNs', 'PoolNet', 'AIonly']\n",
    "method = 'NNs'\n",
    "output_path = '/home/dexter/Downloads/Human_experiments/Visualization'\n",
    "dataset_path = '/home/dexter/Downloads/Human_experiments/Dataset'\n",
    "trial_num = 30\n",
    "participant_num = 15\n",
    "\n",
    "answer = False\n",
    "file_name = ''\n",
    "didyouknow = ''\n",
    "definition = ''\n",
    "sampleimages = ''\n",
    "SAMguessed = ''\n",
    "visualization = ''\n",
    "question = ''\n",
    "\n",
    "vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "\n",
    "vis_path = '{}/{}/{}'.format(output_path, task, method)\n",
    "vis_img_paths = glob.glob(vis_path + '/*.*')\n",
    "adv_vis_path = '{}/{}/{}'.format(output_path, adv_task, method)\n",
    "vis_img_paths += glob.glob(adv_vis_path + '/*.*')\n",
    "\n",
    "artifacts = list()\n",
    "\n",
    "if len(vis_img_paths):\n",
    "    print(\"Task:{} | Method: {}\".format(task, method))\n",
    "    print(len(vis_img_paths))\n",
    "for idx, vis_img_path in enumerate(vis_img_paths):\n",
    "    img_name = vis_img_path.split('{}/'.format(method))[1]\n",
    "    predicted_id = img_name[0:9]\n",
    "    groundtruth_id = img_name[34:43]\n",
    "    predicted_confidence = (img_name.split('.jpeg')[0]).split('_')[-1]\n",
    "    if predicted_id == groundtruth_id:\n",
    "        answer = 'Yes'\n",
    "    else:\n",
    "        answer = 'No'\n",
    "    file_name = img_name\n",
    "    sampleimages = predicted_id + '.jpeg'\n",
    "    predicted_label = id_map.get(predicted_id).split(',')[0]\n",
    "    predicted_label = predicted_label[0].lower() + predicted_label[1:]\n",
    "    if predicted_label[0] in vowels:\n",
    "        didyouknow = '# Have you ever seen an **{}** before?'.format(predicted_label)\n",
    "    else:\n",
    "        didyouknow = '# Have you ever seen a **{}** before?'.format(predicted_label)\n",
    "    \n",
    "    definition = '<h3 style=\\\"text-align: center\\\"> <strong>{}</strong>: {}</h3>'.format(predicted_label, definition_dict[predicted_id])\n",
    "    SAMguessed = '# Sam guessed this is **{}% {}**'.format(predicted_confidence, predicted_label)\n",
    "    visualization = img_name\n",
    "    question = '# Is this **{}**?'.format(predicted_label)\n",
    "    \n",
    "    artifacts.append([answer, file_name, didyouknow, definition, sampleimages, SAMguessed, visualization, question])\n",
    "    \n",
    "import random\n",
    "random.shuffle(artifacts)\n",
    "\n",
    "artifacts_val = list()\n",
    "output_path = '/home/dexter/Downloads/Human_experiments/Stimuli_{}/Validation'.format(task)\n",
    "val_vis_path = '{}/{}'.format(output_path, method)\n",
    "vis_img_paths = glob.glob(val_vis_path + '/*.*')\n",
    "\n",
    "for idx, vis_img_path in enumerate(vis_img_paths):\n",
    "    img_name = vis_img_path.split('{}/'.format(method))[1]\n",
    "    predicted_id = img_name[0:9]\n",
    "    groundtruth_id = img_name[10:19]\n",
    "    predicted_confidence = (img_name.split('.jpeg')[0]).split('_')[-1]\n",
    "    if predicted_id == groundtruth_id:\n",
    "        answer = 'Yes'\n",
    "        print('Yes')\n",
    "    else:\n",
    "        answer = 'No'\n",
    "        print('No')\n",
    "    file_name = img_name\n",
    "    sampleimages = predicted_id + '.jpeg'\n",
    "    predicted_label = id_map.get(predicted_id).split(',')[0]\n",
    "    predicted_label = predicted_label[0].lower() + predicted_label[1:]\n",
    "    if predicted_label[0] in vowels:\n",
    "        didyouknow = '# Have you ever seen an **{}** before?'.format(predicted_label)\n",
    "    else:\n",
    "        didyouknow = '# Have you ever seen a **{}** before?'.format(predicted_label)\n",
    "    definition = '<h3 style=\\\"text-align: center\\\"> <strong>{}</strong>: {}</h3>'.format(predicted_label, definition_dict[predicted_id])\n",
    "    SAMguessed = '# Sam guessed this is **{}% {}**'.format(predicted_confidence, predicted_label)\n",
    "    visualization = img_name\n",
    "    question = '# Is this **{}**?'.format(predicted_label)\n",
    "    \n",
    "    artifacts_val.append([answer, file_name, didyouknow, definition, sampleimages, SAMguessed, visualization, question])\n",
    "\n",
    "# artifacts_val = [artifacts_val[0], artifacts_val[5], artifacts_val[1], artifacts_val[6], artifacts_val[2], artifacts_val[7], artifacts_val[4], artifacts_val[3], artifacts_val[8], artifacts_val[9]]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "if task == 'Natural':\n",
    "    df = pd.read_csv(\"csv_files/spreadsheet_Natural.csv\")  \n",
    "else:\n",
    "    df = pd.read_csv(\"csv_files/spreadsheet_Dog.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "new_columns = ['answer', 'file_name', 'didyouknow', 'definition', 'sampleimages', 'SAMguessed', 'visualization', 'question']\n",
    "default_text = ''\n",
    "for new_column in new_columns:\n",
    "    df[new_column] = ''\n",
    "    for i in range(1,participant_num+1): # 15 people\n",
    "        header_of_new_col = new_column + str(i)\n",
    "        df[header_of_new_col] = ''\n",
    "        \n",
    "df.to_csv('csv_files/spreadsheet1.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_to_dict(l):\n",
    "    d = dict()\n",
    "    for key in l:\n",
    "        d[key] = ''\n",
    "    return d\n",
    "\n",
    "import pandas as pd  \n",
    "df = pd.read_csv(\"csv_files/spreadsheet1.csv\")\n",
    "cols = list(df.columns)\n",
    "d = convert_list_to_dict(cols)\n",
    "\n",
    "for i in range(1,11): # 10 trials in val\n",
    "    new_row = convert_list_to_dict(cols)\n",
    "    new_row['display'] = 'Validation'\n",
    "    new_row['Response1'] = 'Yes'\n",
    "    new_row['Response2'] = 'No'\n",
    "    new_row['Response3'] = 'Yes'\n",
    "    new_row['Response4'] = 'No'\n",
    "    new_row['ANSWER'] = artifacts_val[i-1][0] # To automatically get the results of validation\n",
    "    new_row['file_name'] = artifacts_val[i-1][1]\n",
    "    new_row['didyouknow'] = artifacts_val[i-1][2]\n",
    "    new_row['definition'] = artifacts_val[i-1][3]\n",
    "    new_row['sampleimages'] = artifacts_val[i-1][4]\n",
    "    new_row['SAMguessed'] = artifacts_val[i-1][5]\n",
    "    new_row['visualization'] = artifacts_val[i-1][6]\n",
    "    new_row['question'] = artifacts_val[i-1][7]\n",
    "    new_row['ShowProgressBar'] = '1'\n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "    \n",
    "for i in range(1,trial_num + 1): # 30 trials in test\n",
    "    new_row = convert_list_to_dict(cols)\n",
    "    new_row['display'] = 'Trial'\n",
    "    new_row['Response1'] = 'Yes'\n",
    "    new_row['Response2'] = 'No'\n",
    "    new_row['Response3'] = 'Yes'\n",
    "    new_row['Response4'] = 'No'\n",
    "    for j in range(1,participant_num+1): # 15 people\n",
    "#         print((i-1)*participant_num + j)\n",
    "        new_row['answer' + str(j)] = artifacts[(i-1)*participant_num + j-1][0]\n",
    "        new_row['file_name' + str(j)] = artifacts[(i-1)*participant_num + j-1][1]\n",
    "        new_row['didyouknow' + str(j)] = artifacts[(i-1)*participant_num + j-1][2]\n",
    "        new_row['definition' + str(j)] = artifacts[(i-1)*participant_num + j-1][3]\n",
    "        new_row['sampleimages' + str(j)] = artifacts[(i-1)*participant_num + j-1][4]\n",
    "        new_row['SAMguessed' + str(j)] = artifacts[(i-1)*participant_num + j-1][5]\n",
    "        new_row['visualization' + str(j)] = artifacts[(i-1)*participant_num + j-1][6]\n",
    "        new_row['question' + str(j)] = artifacts[(i-1)*participant_num + j-1][7]\n",
    "        new_row['ShowProgressBar'] = '1'\n",
    "#     Tracer()()\n",
    "#     print(new_row)\n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "    \n",
    "new_row = convert_list_to_dict(cols)\n",
    "new_row['display'] = 'Debrief'\n",
    "df = df.append(new_row, ignore_index=True)    \n",
    "\n",
    "df.to_csv('csv_files/spreadsheet2_{}_{}.csv'.format(task, method), encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
