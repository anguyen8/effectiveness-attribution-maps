{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate attribution maps for GradCAM and EP to run pointing game and localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5Cpmdbql1Gp"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KRNH8n6pl1Gz",
    "outputId": "76fc64f7-9cdd-4367-f881-581d87918e27"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "from torchvision.models import *\n",
    "from visualisation.core.utils import device, image_net_postprocessing\n",
    "from torch import nn\n",
    "from operator import itemgetter\n",
    "from visualisation.core.utils import imshow\n",
    "from IPython.core.debugger import Tracer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1s51UO4ul1HC",
    "outputId": "1981877b-002c-4932-a1ee-3d38a98089b8"
   },
   "outputs": [],
   "source": [
    "layer = 4\n",
    "    \n",
    "model = resnet34(pretrained=True).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6qQeP4Aml1HH"
   },
   "outputs": [],
   "source": [
    "# %matplotlib notebook \n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch \n",
    "from utils import *\n",
    "from PIL import Image\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]= 16,8\n",
    "\n",
    "\n",
    "def make_dir(path):\n",
    "    if os.path.isdir(path) == False:\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwZvXYWFl1HR"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from visualisation.core.utils import device \n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor, Resize, Compose, ToPILImage\n",
    "from visualisation.core import *\n",
    "from visualisation.core.utils import image_net_preprocessing\n",
    "\n",
    "size = 224\n",
    "\n",
    "# Pre-process the image and convert into a tensor\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "img_num = 50\n",
    "\n",
    "# methods = ['Conf', 'GradCAM', 'EP', 'SHAP', 'NNs', 'PoolNet', 'AIonly']\n",
    "methods = ['Conf', 'GradCAM', 'EP', 'NNs', 'PoolNet', 'AIonly']\n",
    "\n",
    "task = 'Adversarial_Nat'\n",
    "# Adversarial_Nat\n",
    "\n",
    "output_path = '/home/dexter/Downloads/Human_experiments/Visualization'\n",
    "dataset_path = '/home/dexter/Downloads/Human_experiments/Dataset'\n",
    "make_dir('{}/{}'.format(output_path,task))\n",
    "make_dir('{}/{}/Conf/'.format(output_path,task))\n",
    "make_dir('{}/{}/GradCAM/'.format(output_path,task))\n",
    "make_dir('{}/{}/EP/'.format(output_path,task))\n",
    "# make_dir('Pilot_study2/{}/SHAP/'.format(task))\n",
    "make_dir('{}/{}/PoolNet/'.format(output_path,task))\n",
    "make_dir('{}/{}/NNs/'.format(output_path,task))\n",
    "# test_image_paths = glob.glob('/home/dexter/Downloads/Pilot_study2/{}/mixed_images/*.*'.format(task))\n",
    "corrects_bin1 = glob.glob('{}/{}/correct_bin1_images/*.*'.format(dataset_path,task))\n",
    "wrongs_bin1 = glob.glob('{}/{}/wrong_bin1_images/*.*'.format(dataset_path,task))\n",
    "corrects_bin2 = glob.glob('{}/{}/correct_bin2_images/*.*'.format(dataset_path,task))\n",
    "wrongs_bin2 = glob.glob('{}/{}/wrong_bin2_images/*.*'.format(dataset_path,task))\n",
    "corrects_bin3 = glob.glob('{}/{}/correct_bin3_images/*.*'.format(dataset_path,task))\n",
    "wrongs_bin3 = glob.glob('{}/{}/wrong_bin3_images/*.*'.format(dataset_path,task))\n",
    "# print(test_image_paths)\n",
    "# test_inputs = list()\n",
    "test_images = list()\n",
    "\n",
    "modified_img = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQ2SjgvMl1IJ"
   },
   "outputs": [],
   "source": [
    "# Added for loading ImageNet classes\n",
    "def load_imagenet_label_map():\n",
    "    \"\"\"\n",
    "    Load ImageNet label dictionary.\n",
    "    return:\n",
    "    \"\"\"\n",
    "\n",
    "    input_f = open(\"input_txt_files/imagenet_classes.txt\")\n",
    "    label_map = {}\n",
    "    for line in input_f:\n",
    "        parts = line.strip().split(\": \")\n",
    "        (num, label) = (int(parts[0]), parts[1].replace('\"', \"\"))\n",
    "        label_map[num] = label\n",
    "\n",
    "    input_f.close()\n",
    "    return label_map\n",
    "\n",
    "\n",
    "# Added for loading ImageNet classes\n",
    "def load_imagenet_id_map():\n",
    "    \"\"\"\n",
    "    Load ImageNet ID dictionary.\n",
    "    return;\n",
    "    \"\"\"\n",
    "\n",
    "    input_f = open(\"input_txt_files/synset_words.txt\")\n",
    "    label_map = {}\n",
    "    for line in input_f:\n",
    "        parts = line.strip().split(\" \")\n",
    "        (num, label) = (parts[0], ' '.join(parts[1:]))\n",
    "        label_map[num] = label\n",
    "\n",
    "    input_f.close()\n",
    "    return label_map\n",
    "\n",
    "def convert_imagenet_label_to_id(label_map, key_list, val_list, prediction_class):\n",
    "    \"\"\"\n",
    "    Convert imagenet label to ID: for example - 245 -> \"French bulldog\" -> n02108915\n",
    "    :param label_map:\n",
    "    :param key_list:\n",
    "    :param val_list:\n",
    "    :param prediction_class:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    class_to_label = label_map[prediction_class]\n",
    "    prediction_id = key_list[val_list.index(class_to_label)]\n",
    "    return prediction_id\n",
    "\n",
    "\n",
    "# gt_dict = load_imagenet_validation_gt()\n",
    "id_map = load_imagenet_id_map()\n",
    "label_map = load_imagenet_label_map()\n",
    "\n",
    "key_list = list(id_map.keys())\n",
    "val_list = list(id_map.values())\n",
    "\n",
    "def convert_imagenet_id_to_label(label_map, key_list, val_list, class_id):\n",
    "    \"\"\"\n",
    "    Convert imagenet label to ID: for example - n02108915 -> \"French bulldog\" -> 245\n",
    "    :param label_map:\n",
    "    :param key_list:\n",
    "    :param val_list:\n",
    "    :param prediction_class:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return key_list.index(str(class_id))\n",
    "\n",
    "from torchray.attribution.extremal_perturbation import extremal_perturbation, contrastive_reward\n",
    "from torchray.attribution.grad_cam import grad_cam\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "def get_EP_saliency_maps(model, path):\n",
    "        img_index = (path.split('.jpeg')[0]).split('images/')[1]\n",
    "        img = PIL.Image.open(path)\n",
    "        x = transform(img).unsqueeze(0).to(device)\n",
    "        out = model(x)\n",
    "        p = torch.nn.functional.softmax(out, dim=1)\n",
    "        score, index = torch.topk(p, 1)\n",
    "        category_id_1 = index[0][0].item()\n",
    "\n",
    "        masks, energy = extremal_perturbation(\n",
    "            model, x, category_id_1,\n",
    "            areas=[0.025, 0.05, 0.1, 0.2],\n",
    "            num_levels=8,\n",
    "            step=7,\n",
    "            sigma=7 * 3,\n",
    "            max_iter=800,\n",
    "            debug=False,\n",
    "            jitter=True,\n",
    "            smooth=0.09,\n",
    "            perturbation='blur'\n",
    "        )\n",
    "        saliency = masks.sum(dim=0, keepdim=True)\n",
    "        saliency = saliency.detach()\n",
    "        saliency_t = saliency.cpu().detach().numpy()[0, 0, :]\n",
    "        \n",
    "        saliency_path = 'saliency_maps/EP_resnet34/'\n",
    "        if not (os.path.exists(saliency_path)):\n",
    "            os.mkdir(saliency_path)\n",
    "        img_index = img_index[10:33]\n",
    "        np.save(os.path.join(saliency_path, \"{}.npy\".format(img_index)), saliency_t)\n",
    "\n",
    "        return (saliency[0].to('cpu')), (masks[0].to('cpu')), (masks[1].to('cpu')), (masks[2].to('cpu')) , (masks[3].to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import os.path\n",
    "from visualisation.core.utils import tensor2cam\n",
    "postprocessing_t = image_net_postprocessing\n",
    "import cv2 as cv\n",
    "import sys\n",
    "\n",
    "imagenet_train_path = '/home/dexter/Downloads/train'\n",
    "\n",
    "## Creating colormap\n",
    "cMap = 'Reds'\n",
    "\n",
    "id_list= list()\n",
    "conf_dict = {}\n",
    "eps=1e-5\n",
    "cnt = 0\n",
    "K = 3 # Change to your expected number of nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'Conf'\n",
    "test_image_paths = corrects_bin1[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "                    wrongs_bin1[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "                    corrects_bin2[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "                    wrongs_bin2[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "                    corrects_bin3[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "                    wrongs_bin3[methods.index(method)*img_num:methods.index(method)*img_num + img_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'GradCAM'\n",
    "\n",
    "for idx, image_path in enumerate(test_image_paths):\n",
    "    print(idx + 1)\n",
    "    distance_dict = dict()\n",
    "    neighbors = list()\n",
    "    categories_confidences = list()\n",
    "    confidences= list ()\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    input_image = img.resize((size,size), Image.ANTIALIAS)\n",
    "\n",
    "    image_name = (image_path.split('.jpeg')[0]).split('images/')[1]\n",
    "    print(image_name)\n",
    "\n",
    "    # Get the ground truth of the input image\n",
    "    gt_label_id = image_path.split('val_')[1][9:18]\n",
    "\n",
    "    \n",
    "    gt_label = id_map.get(gt_label_id)\n",
    "    id = key_list.index(gt_label_id)\n",
    "    gt_label = gt_label.split(',')[0]\n",
    "\n",
    "\n",
    "    # Get the prediction for the input image\n",
    "    img = Image.open(image_path)\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    out = model(x)\n",
    "    p = torch.nn.functional.softmax(out, dim=1)\n",
    "    score, index = torch.topk(p, 1)\n",
    "    input_category_id = index[0][0].item()\n",
    "    predicted_confidence = score[0][0].item()\n",
    "    predicted_confidence = (\"%.2f\") %(predicted_confidence)\n",
    "#     print(predicted_confidence)\n",
    "\n",
    "\n",
    "    input_prediction_id = convert_imagenet_label_to_id(label_map, key_list, val_list, input_category_id)\n",
    "    predicted_label = id_map.get(input_prediction_id).split(',')[0]\n",
    "    predicted_label = predicted_label[0].lower() + predicted_label[1:]\n",
    "\n",
    "    conf_dict[image_name] = predicted_confidence\n",
    "\n",
    "#     GRAD-CAM\n",
    "    saliency = grad_cam(\n",
    "        model, x, input_category_id,\n",
    "        saliency_layer='layer4',\n",
    "        resize=True\n",
    "    )\n",
    "#     Tracer()()\n",
    "    img_index = (image_path.split('.jpeg')[0]).split('images/')[1]\n",
    "    img_index = img_index[10:33]\n",
    "    if not (os.path.exists(saliency_path)):\n",
    "        os.mkdir(saliency_path)\n",
    "    saliency_path = 'saliency_maps/GradCAM_resnet34/'\n",
    "    saliency *= 1.0/saliency.max()\n",
    "    GradCAM = saliency[0][0].cpu().detach().numpy()\n",
    "    np.save(os.path.join(saliency_path, \"{}.npy\".format(img_index)), GradCAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'EP'\n",
    "for idx, image_path in enumerate(test_image_paths):\n",
    "    print(idx + 1)\n",
    "    # Extremal Perturbation\n",
    "    get_EP_saliency_maps(model, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'PoolNet'\n",
    "from shutil import copyfile, rmtree\n",
    "def rm_and_mkdir(path):\n",
    "    if os.path.isdir(path) == True:\n",
    "        rmtree(path)\n",
    "    os.mkdir(path)\n",
    "\n",
    "# Prepare dataset\n",
    "rm_and_mkdir('/home/dexter/Downloads/run-0/run-0-sal-p/')\n",
    "rm_and_mkdir('/home/dexter/Downloads/PoolNet-master/data/PASCALS/Imgs/')\n",
    "if os.path.isdir('/home/dexter/Downloads/PoolNet-master/data/PASCALS/test.lst'):\n",
    "    os.remove('/home/dexter/Downloads/PoolNet-master/data/PASCALS/test.lst')\n",
    "\n",
    "src_paths = test_image_paths\n",
    "for src_path in src_paths:\n",
    "    dst_path = '/home/dexter/Downloads/PoolNet-master/data/PASCALS/Imgs/' + src_path.split('images/')[1]\n",
    "    copyfile(src_path, dst_path)\n",
    "\n",
    "cmd = 'ls /home/dexter/Downloads/PoolNet-master/data/PASCALS/Imgs/ > /home/dexter/Downloads/PoolNet-master/data/PASCALS/test.lst'\n",
    "os.system(cmd)\n",
    "cmd = 'python /home/dexter/Downloads/PoolNet-master/main.py --mode=\\'test\\' --model=\\'/home/dexter/Downloads/run-0/run-0/models/final.pth\\' --test_fold=\\'/home/dexter/Downloads/run-0/run-0-sal-p/\\' --sal_mode=\\'p\\''\n",
    "os.system(cmd)\n",
    "\n",
    "\n",
    "npy_file_paths = glob.glob('/home/dexter/Downloads/run-0/run-0-sal-p/*.*')\n",
    "print(len(npy_file_paths))\n",
    "for idx, npy_file_path in enumerate(npy_file_paths): \n",
    "    img_index = npy_file_path.split('/home/dexter/Downloads/run-0/run-0-sal-p/')[1]\n",
    "    img_index = img_index[10:33]\n",
    "    saliency_path = 'saliency_maps/SOD_resnet34/'\n",
    "    dst_path = saliency_path + img_index + '.npy'\n",
    "    copyfile(npy_file_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "NearestNeighbors_v2_vs_CAM_modified.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
