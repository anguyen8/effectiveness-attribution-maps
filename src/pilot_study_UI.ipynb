{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the UI for pilot study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from IPython.display import HTML\n",
    "\n",
    "# HTML('''<script>\n",
    "# code_show=true; \n",
    "# function code_toggle() {\n",
    "#  if (code_show){\n",
    "#  $('div.input').hide();\n",
    "#  } else {\n",
    "#  $('div.input').show();\n",
    "#  }\n",
    "#  code_show = !code_show\n",
    "# } \n",
    "# $( document ).ready(code_toggle);\n",
    "# </script>\n",
    "# <form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import matplotlib.image as mpimg\n",
    "import timeit\n",
    "\n",
    "labels_path = os.getenv(\"HOME\") + '/.torch/models/imagenet_class_index.json'\n",
    "with open(labels_path) as json_data:\n",
    "    idx_to_labels = json.load(json_data)\n",
    "    \n",
    "################################ ABOVE FOR SHAP\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "from torchvision.models import *\n",
    "from visualisation.core.utils import device, image_net_postprocessing\n",
    "from torch import nn\n",
    "from operator import itemgetter\n",
    "from visualisation.core.utils import imshow\n",
    "from IPython.core.debugger import Tracer\n",
    "from IPython.display import clear_output\n",
    "\n",
    "task = 'Natural'\n",
    "method = 'NNs' # Change this to Conf, EP or ... \n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch \n",
    "from utils import *\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "if method == 'NNs':\n",
    "    size = 40\n",
    "elif method == 'GradCAM' or method == 'EP' or method == 'SHAP' or method == 'PoolNet':\n",
    "    size = 20\n",
    "elif method == 'Conf':\n",
    "    size = 10\n",
    "else:\n",
    "    raise ValueError('Not Implemented!')\n",
    "    \n",
    "answer_dict = dict()\n",
    "\n",
    "file_name = 'Pilot_study2/{}/{}.csv'.format(task, method)\n",
    "test_image_paths = glob.glob('Pilot_study2/{}/{}/*.*'.format(task, method))\n",
    "test_images = list(map(lambda x: mpimg.imread(x), test_image_paths))\n",
    "for idx, test_image in enumerate(test_images):\n",
    "    print(idx)\n",
    "    if idx == 10:\n",
    "        break\n",
    "    print(test_image_paths[idx])\n",
    "    img_idx = test_image_paths[idx].split('.jpeg')[0].split('{}/'.format(method))[1]\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(size,size))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(test_image)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    a = input(\"Press 1 if you agree, 0 if you disagree:\")\n",
    "    while a not in ['0', '1']:\n",
    "        a = input(\"Input must be 0 or 1. Press 1 if you agree, 0 if you disagree:\")\n",
    "        \n",
    "    stop = timeit.default_timer()\n",
    "    time_taken = stop-start\n",
    "    a = int(a)\n",
    "    if a == 1:\n",
    "        answer_dict[img_idx] = [1, 0, time_taken]\n",
    "    else:\n",
    "        answer_dict[img_idx] = [0, 1, time_taken]\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    for key in answer_dict.keys():\n",
    "        file.write(\"%s,%s,%s,%s\\n\" %(key, answer_dict[key][0], answer_dict[key][1], answer_dict[key][2]))\n",
    "\n",
    "# Evaluate accuracy\n",
    "correct_images = glob.glob('/home/dexter/Downloads/Pilot_study2/{}/correct/*.*'.format(task))\n",
    "wrong_images = glob.glob('/home/dexter/Downloads/Pilot_study2/{}/wrong/*.*'.format(task))\n",
    "\n",
    "correct_indices = list()\n",
    "wrong_indices = list()\n",
    "\n",
    "gt_dict = dict()\n",
    "\n",
    "for correct_image in correct_images:\n",
    "    image_idx = (correct_image.split('.jpeg')[0]).split('val_')[1]\n",
    "    correct_indices.append(image_idx)\n",
    "    \n",
    "gt_dict = dict(zip(correct_indices, [1]*len(correct_indices)))\n",
    "\n",
    "for wrong_image in wrong_images:\n",
    "    image_idx = (wrong_image.split('.jpeg')[0]).split('wrong/')[1]\n",
    "    wrong_indices.append(image_idx)\n",
    "\n",
    "gt_dict = {**dict(zip(correct_indices, [True]*len(correct_indices))), **dict(zip(wrong_indices, [False]*len(wrong_indices)))}\n",
    "\n",
    "results = {}\n",
    "reader = csv.reader(open(file_name))\n",
    "\n",
    "time_taken = list()\n",
    "for idx, row in enumerate(reader):\n",
    "    key = row[0]\n",
    "    time_taken.append(float(row[3]))\n",
    "    if row[1] == '1':\n",
    "        results[key] = True\n",
    "    elif row[2] == '1':\n",
    "        results[key] = False\n",
    "    else:\n",
    "        print(row)\n",
    "        raise ValueError('Missing data in this row!')\n",
    "\n",
    "result_temp = dict()\n",
    "for key, val in results.items():\n",
    "    k = key.split(\".jpeg\")[0]\n",
    "    result_temp[k] = val\n",
    "    \n",
    "\n",
    "# Compute accuracy\n",
    "shared_items = {k: gt_dict[k] for k in gt_dict if k in result_temp and gt_dict[k] == result_temp[k]}\n",
    "print(\"The total number of correct answers is: {}\".format(len(shared_items)))\n",
    "print(\"The max time taken for an image is: {}\".format(max(time_taken)))\n",
    "print(\"The avg time taken for an image is: {}\".format(sum(time_taken)/len(time_taken)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "import matplotlib.image as mpimg\n",
    "import timeit\n",
    "\n",
    "labels_path = os.getenv(\"HOME\") + '/.torch/models/imagenet_class_index.json'\n",
    "with open(labels_path) as json_data:\n",
    "    idx_to_labels = json.load(json_data)\n",
    "    \n",
    "################################ ABOVE FOR SHAP\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "from torchvision.models import *\n",
    "from visualisation.core.utils import device, image_net_postprocessing\n",
    "from torch import nn\n",
    "from operator import itemgetter\n",
    "from visualisation.core.utils import imshow\n",
    "from IPython.core.debugger import Tracer\n",
    "from IPython.display import clear_output\n",
    "\n",
    "task = 'Dog'\n",
    "img_per_method = 5\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch \n",
    "import random\n",
    "from utils import *\n",
    "from PIL import Image\n",
    "\n",
    "adv_correct_desc = 0    \n",
    "answer_dict = dict()\n",
    "test_image_paths = list()\n",
    "\n",
    "file_name = 'Pilot_study2/{}.csv'.format(task)\n",
    "test_folders = glob.glob('Pilot_study2/{}/*'.format(task))\n",
    "for test_folder in test_folders:\n",
    "    test_image_paths += glob.glob(test_folder + '/*.*')\n",
    "test_image_paths = random.sample(test_image_paths, len(test_image_paths)) # Shuffle the list\n",
    "\n",
    "test_folders = glob.glob('Pilot_study2/Adversarial_{}/*'.format(task))\n",
    "for test_folder in test_folders:\n",
    "    test_image_paths += glob.glob(test_folder + '/*.*')\n",
    "test_image_paths = random.sample(test_image_paths, len(test_image_paths)) # Shuffle the list\n",
    "# test_image_paths = test_image_paths[:10]\n",
    "test_images = list(map(lambda x: mpimg.imread(x), test_image_paths))\n",
    "for idx, test_image in enumerate(test_images):\n",
    "#     if idx == 10:\n",
    "#         break\n",
    "    print(\"{}/{}\".format(idx+1, len(test_images)))\n",
    "    print(test_image_paths[idx])\n",
    "    task_method = test_image_paths[idx].split('Pilot_study2/')[1].split('val_')[0]\n",
    "        \n",
    "    if 'NNs' in task_method:\n",
    "        size = 40\n",
    "    elif 'GradCAM' in task_method or 'EP' in task_method or 'SHAP' in task_method or 'PoolNet' in task_method:\n",
    "        size = 20\n",
    "    elif 'Conf' in task_method:\n",
    "        size = 10\n",
    "    else:\n",
    "        raise ValueError('Not Implemented!')\n",
    "        \n",
    "    img_idx = test_image_paths[idx].split('.jpeg')[0].split(task_method)[1]\n",
    "    img_idx = task_method + img_idx\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(size,size))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(test_image)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    a = input(\"Press 1 if you agree, 0 if you disagree:\")\n",
    "    while a not in ['0', '1']:\n",
    "        a = input(\"Input must be 0 or 1. Press 1 if you agree, 0 if you disagree:\")\n",
    "        \n",
    "    stop = timeit.default_timer()\n",
    "    time_taken = stop-start\n",
    "    a = int(a)\n",
    "    if a == 1:\n",
    "        answer_dict[img_idx] = [1, 0, time_taken]\n",
    "    else:\n",
    "        answer_dict[img_idx] = [0, 1, time_taken]\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "with open(file_name, 'w') as file:\n",
    "    for key in answer_dict.keys():\n",
    "        file.write(\"%s,%s,%s,%s\\n\" %(key, answer_dict[key][0], answer_dict[key][1], answer_dict[key][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'Dog'\n",
    "file_name = 'Pilot_study2/{}.csv'.format(task)\n",
    "\n",
    "reader = csv.reader(open(file_name))\n",
    "answer_dict = dict()\n",
    "time_taken = list()\n",
    "for idx, row in enumerate(reader):\n",
    "    answer_dict[row[0]] = row[1:]\n",
    "    time_taken.append(float(row[3]))\n",
    "\n",
    "# Evaluate accuracy\n",
    "correct_images = glob.glob('/home/dexter/Downloads/Pilot_study2/{}/correct_images/*.*'.format(task))\n",
    "wrong_images = glob.glob('/home/dexter/Downloads/Pilot_study2/{}/wrong_images/*.*'.format(task))\n",
    "\n",
    "corrects_bin1 = dict(zip([x.split('.jpeg')[0].split('correct_bin1_images/')[1] for x in glob.glob('/home/dexter/Downloads/Pilot_study2/{}/correct_bin1_images/*.*'.format(task))], [True]*img_per_method*7))\n",
    "corrects_bin2 = dict(zip([x.split('.jpeg')[0].split('correct_bin2_images/')[1] for x in glob.glob('/home/dexter/Downloads/Pilot_study2/{}/correct_bin2_images/*.*'.format(task))], [True]*img_per_method*7))\n",
    "corrects_bin3 = dict(zip([x.split('.jpeg')[0].split('correct_bin3_images/')[1] for x in glob.glob('/home/dexter/Downloads/Pilot_study2/{}/correct_bin3_images/*.*'.format(task))], [True]*img_per_method*7))\n",
    "\n",
    "wrongs_bin1 = dict(zip([x.split('.jpeg')[0].split('wrong_bin1_images/')[1] for x in glob.glob('/home/dexter/Downloads/Pilot_study2/{}/wrong_bin1_images/*.*'.format(task))], [False]*img_per_method*7))\n",
    "wrongs_bin2 = dict(zip([x.split('.jpeg')[0].split('wrong_bin2_images/')[1] for x in glob.glob('/home/dexter/Downloads/Pilot_study2/{}/wrong_bin2_images/*.*'.format(task))], [False]*img_per_method*7))\n",
    "wrongs_bin3 = dict(zip([x.split('.jpeg')[0].split('wrong_bin3_images/')[1] for x in glob.glob('/home/dexter/Downloads/Pilot_study2/{}/wrong_bin3_images/*.*'.format(task))], [False]*img_per_method*7))\n",
    "\n",
    "adv_wrongs_bin1 = dict(zip([x.split('.jpeg')[0].split('ILSVRC2012_')[1][:22] for x in glob.glob('/home/dexter/Downloads/Pilot_study2/Adversarial_{}/wrong_bin1_images/*.*'.format('Dog'))], [False]*img_per_method*7))\n",
    "adv_wrongs_bin2 = dict(zip([x.split('.jpeg')[0].split('ILSVRC2012_')[1][:22] for x in glob.glob('/home/dexter/Downloads/Pilot_study2/Adversarial_{}/wrong_bin2_images/*.*'.format('Dog'))], [False]*img_per_method*7))\n",
    "adv_wrongs_bin3 = dict(zip([x.split('.jpeg')[0].split('ILSVRC2012_')[1][:22] for x in glob.glob('/home/dexter/Downloads/Pilot_study2/Adversarial_{}/wrong_bin3_images/*.*'.format('Dog'))], [False]*img_per_method*7))\n",
    "\n",
    "correct_indices = list()\n",
    "wrong_indices = list()\n",
    "\n",
    "gt_dict = dict()\n",
    "\n",
    "for correct_image in correct_images:\n",
    "    image_idx = (correct_image.split('.jpeg')[0]).split('correct_images/')[1]\n",
    "    correct_indices.append(image_idx)\n",
    "    \n",
    "gt_dict = dict(zip(correct_indices, [1]*len(correct_indices)))\n",
    "\n",
    "for wrong_image in wrong_images:\n",
    "    image_idx = (wrong_image.split('.jpeg')[0]).split('wrong_images/')[1]\n",
    "    wrong_indices.append(image_idx)\n",
    "\n",
    "gt_dict = {**dict(zip(correct_indices, [True]*len(correct_indices))), **dict(zip(wrong_indices, [False]*len(wrong_indices)))}\n",
    "\n",
    "print(\"The max time taken for an image is: {}\".format(max(time_taken)))\n",
    "print(\"The avg time taken for an image is: {}\".format(sum(time_taken)/len(time_taken)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer()()\n",
    "methods = ['Conf', 'EP', 'GradCAM', 'NNs', 'PoolNet', 'SHAP'] # alphabettically sorted\n",
    "# print(sorted(answer_dict.keys()))\n",
    "adv_keys = sorted(answer_dict.keys())[:img_per_method*3*6] # 3 bins 6 methods\n",
    "unattacked_keys = sorted(answer_dict.keys())[img_per_method*3*6:img_per_method*3*6 + img_per_method*2*3*6] # correct/wrong 3 bins 6 methods\n",
    "adv_dict = dict()\n",
    "unattacked_dict = dict()\n",
    "for method in methods:\n",
    "    tmp_dict = dict()\n",
    "    time_taken = list()\n",
    "    for k in adv_keys[methods.index(method)*img_per_method*3:methods.index(method)*img_per_method*3 + img_per_method*3]:\n",
    "        key = k.split('ILSVRC2012_')[1][:22]\n",
    "        time_taken.append(float(answer_dict[k][2]))\n",
    "        if answer_dict[k][0] == '1':\n",
    "            value = True\n",
    "        elif answer_dict[k][1] == '1':\n",
    "            value = False\n",
    "        tmp_dict[key] = value\n",
    "    adv_dict[method] = tmp_dict\n",
    "    method_result_adv = adv_dict[method]\n",
    "    \n",
    "    tmp_dict = dict()\n",
    "    time_taken = list()\n",
    "    for k in unattacked_keys[methods.index(method)*img_per_method*2*3:methods.index(method)*img_per_method*2*3 + img_per_method*2*3]:\n",
    "        key = k.split(method+'/')[1]\n",
    "        time_taken.append(float(answer_dict[k][2]))\n",
    "        if answer_dict[k][0] == '1':\n",
    "            value = True\n",
    "        elif answer_dict[k][1] == '1':\n",
    "            value = False\n",
    "        tmp_dict[key] = value\n",
    "    unattacked_dict[method] = tmp_dict\n",
    "    method_result_unattacked = unattacked_dict[method]\n",
    "    shared_items = {k: gt_dict[k] for k in gt_dict if k in method_result_unattacked and gt_dict[k] == method_result_unattacked[k]}\n",
    "\n",
    "print(\"{}\".format(task))\n",
    "print(\"Results on unattacked images:\")\n",
    "for method in methods:\n",
    "    method_result_unattacked = unattacked_dict[method]\n",
    "    shared_items = {k: gt_dict[k] for k in gt_dict if k in method_result_unattacked and gt_dict[k] == method_result_unattacked[k]}\n",
    "    print('{}: {}/{}'.format(method,len(shared_items),img_per_method*2*3))\n",
    "    \n",
    "print(\"Results on adversarial images:\")\n",
    "for method in methods:\n",
    "    method_result_adv = adv_dict[method]\n",
    "    print('{}: {}/{}'.format(method, sum(value == 0 for value in method_result_adv.values()), img_per_method*3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
