{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Classify ImageNEt and Dogs images by confidence intervals, remove low-quality images, remove MINDs\n",
    "2. Generate explanations for COnf, GradCAM, SHAP, 3-NN\n",
    "3. Generate samples images and intro images for Dogs and ImageNet\n",
    "4. Generate visualizations for Gorilla Instructions\n",
    "5. Generate validation image aggregations, class samples, ImageNEt/Dogs distribution for paper writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models import *\n",
    "from visualisation.core.utils import device, image_net_postprocessing, image_net_preprocessing\n",
    "from torch import nn\n",
    "from operator import itemgetter\n",
    "from visualisation.core.utils import imshow\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "import os\n",
    "from torchvision import models\n",
    "from shutil import copyfile, rmtree\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from PIL import Image\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]= 16,8\n",
    "\n",
    "\n",
    "from torchvision.transforms import ToTensor, Resize, Compose, ToPILImage\n",
    "from visualisation.core import *\n",
    "\n",
    "size= 224\n",
    "\n",
    "# Pre-process the image and convert into a tensor\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n02097474\n"
     ]
    }
   ],
   "source": [
    "def make_dir(path):\n",
    "    if os.path.isdir(path) == False:\n",
    "        os.mkdir(path)\n",
    "\n",
    "# Added for loading ImageNet classes\n",
    "def load_imagenet_label_map():\n",
    "    \"\"\"\n",
    "    Load ImageNet label dictionary.\n",
    "    return:\n",
    "    \"\"\"\n",
    "\n",
    "    input_f = open(\"input_txt_files/imagenet_classes.txt\")\n",
    "    label_map = {}\n",
    "    for line in input_f:\n",
    "        parts = line.strip().split(\": \")\n",
    "        (num, label) = (int(parts[0]), parts[1].replace('\"', \"\"))\n",
    "        label_map[num] = label\n",
    "\n",
    "    input_f.close()\n",
    "    return label_map\n",
    "\n",
    "\n",
    "# Added for loading ImageNet classes\n",
    "def load_imagenet_id_map():\n",
    "    \"\"\"\n",
    "    Load ImageNet ID dictionary.\n",
    "    return;\n",
    "    \"\"\"\n",
    "\n",
    "    input_f = open(\"input_txt_files/synset_words.txt\")\n",
    "    label_map = {}\n",
    "    for line in input_f:\n",
    "        parts = line.strip().split(\" \")\n",
    "        (num, label) = (parts[0], ' '.join(parts[1:]))\n",
    "        label_map[num] = label\n",
    "\n",
    "    input_f.close()\n",
    "    return label_map\n",
    "\n",
    "def load_imagenet_validation_gt():\n",
    "    count = 0\n",
    "    input_f = open(\"input_txt_files/ILSVRC2012_validation_ground_truth.txt\")\n",
    "    gt_dict = {}\n",
    "    while True:\n",
    "        count += 1\n",
    "        \n",
    "        # Get the next line\n",
    "        line = input_f.readline()\n",
    "        \n",
    "        # if line is empty, EOL is reached\n",
    "        if not line:\n",
    "            break\n",
    "        gt_dict [count] = int(line.strip())\n",
    "\n",
    "    input_f.close()\n",
    "    return gt_dict\n",
    "\n",
    "def convert_imagenet_label_to_id(label_map, key_list, val_list, prediction_class):\n",
    "    \"\"\"\n",
    "    Convert imagenet label to ID: for example - 245 -> \"French bulldog\" -> n02108915\n",
    "    :param label_map:\n",
    "    :param key_list:\n",
    "    :param val_list:\n",
    "    :param prediction_class:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    class_to_label = label_map[prediction_class]\n",
    "    prediction_id = key_list[val_list.index(class_to_label)]\n",
    "    return prediction_id\n",
    "\n",
    "gt_dict = load_imagenet_validation_gt()\n",
    "id_map = load_imagenet_id_map()\n",
    "label_map = load_imagenet_label_map()\n",
    "\n",
    "key_list = list(id_map.keys())\n",
    "val_list = list(id_map.values())\n",
    "\n",
    "print(key_list[200])\n",
    "\n",
    "def convert_imagenet_id_to_label(key_list, class_id):\n",
    "    \"\"\"\n",
    "    Convert imagenet label to ID: for example - n02108915 -> \"French bulldog\" -> 245\n",
    "    :param label_map:\n",
    "    :param key_list:\n",
    "    :param val_list:\n",
    "    :param prediction_class:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return key_list.index(str(class_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet_dog_label():\n",
    "    count = 0\n",
    "    dog_id_list = list()\n",
    "    input_f = open(\"input_txt_files/dog_type.txt\")\n",
    "    for line in input_f:\n",
    "        dog_id = (line.split('-')[0])\n",
    "        dog_id_list.append(dog_id)\n",
    "    return dog_id_list\n",
    "\n",
    "dogs_id = load_imagenet_dog_label()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Prepare images for all experiments\n",
    "UPPER_THRESH = 0.8\n",
    "LOWER_THRESH = 0.2\n",
    "\n",
    "NAT_DATASET_TRAIN_INTERVAL = '/home/dexter/Downloads/Dataset/Interval_train_nat/'\n",
    "DOG_DATASET_TRAIN_INTERVAL = '/home/dexter/Downloads/Dataset/Interval_train_dog/'\n",
    "NAT_DATASET_INTERVAL = '/home/dexter/Downloads/Dataset/Interval_nat/'\n",
    "DOG_DATASET_INTERVAL = '/home/dexter/Downloads/Dataset/Interval_dog/'\n",
    "ADV_NAT_INTERVAL = '/home/dexter/Downloads/Dataset/Interval_adv_nat/'\n",
    "ADV_DOG_INTERVAL = '/home/dexter/Downloads/Dataset/Interval_adv_dog/'\n",
    "\n",
    "NAT_RESNET34_CORRECT = '/home/dexter/Downloads/Dataset/Natural_correct_resnet34/'\n",
    "NAT_RESNET34_WRONG = '/home/dexter/Downloads/Dataset/Natural_wrong_resnet34/'\n",
    "NAT_RESNET34_HARD = '/home/dexter/Downloads/Dataset/Natural_hard_images_resnet34/'\n",
    "NAT_RESNET34_EASY = '/home/dexter/Downloads/Dataset/Natural_easy_images_resnet34/'\n",
    "NAT_ADV_RESNET34 = '/home/dexter/Downloads/Dataset/Natural_Adv_images_resnet34/'\n",
    "NAT_RESNET34_CORRECT_UPPER_THRESH = '/home/dexter/Downloads/Dataset/Natural_correct_resnet34_above_08/'\n",
    "NAT_RESNET34_CORRECT_LOWER_THRESH = '/home/dexter/Downloads/Dataset/Natural_correct_resnet34_below_02/'\n",
    "NAT_RESNET34_WRONG_UPPER_THRESH = '/home/dexter/Downloads/Dataset/Natural_wrong_resnet34_above_08/'\n",
    "NAT_RESNET34_WRONG_LOWER_THRESH = '/home/dexter/Downloads/Dataset/Natural_wrong_resnet34_below_02/'\n",
    "NAT_ATTACKED = '/home/dexter/Downloads/Dataset/Adv_nat_examples/'\n",
    "NAT_ATTACKED_VERIFIED = '/home/dexter/Downloads/Dataset/Adv_nat_examples_verified/'\n",
    "\n",
    "DOG_RESNET34_CORRECT = '/home/dexter/Downloads/Dataset/Dog_correct_resnet34/'\n",
    "DOG_RESNET34_WRONG = '/home/dexter/Downloads/Dataset/Dog_wrong_resnet34/'\n",
    "DOG_RESNET34_HARD = '/home/dexter/Downloads/Dataset/Dog_hard_images_resnet34/'\n",
    "DOG_RESNET34_EASY = '/home/dexter/Downloads/Dataset/Dog_easy_images_resnet34/'\n",
    "DOG_ADV_RESNET34 = '/home/dexter/Downloads/Dataset/Dog_Adv_images_resnet34/'\n",
    "DOG_RESNET34_CORRECT_UPPER_THRESH = '/home/dexter/Downloads/Dataset/Dog_correct_resnet34_above_08/'\n",
    "DOG_RESNET34_CORRECT_LOWER_THRESH = '/home/dexter/Downloads/Dataset/Dog_correct_resnet34_below_02/'\n",
    "DOG_RESNET34_WRONG_UPPER_THRESH = '/home/dexter/Downloads/Dataset/Dog_wrong_resnet34_above_08/'\n",
    "DOG_RESNET34_WRONG_LOWER_THRESH = '/home/dexter/Downloads/Dataset/Dog_wrong_resnet34_below_02/'\n",
    "DOG_ATTACKED = '/home/dexter/Downloads/Dataset/Adv_dog_examples/'\n",
    "DOG_ATTACKED_VERIFIED = '/home/dexter/Downloads/Dataset/Adv_dog_examples_verified/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify ImageNet and Dogs by confidence interval.Remove low-quality images, MIND samples\n",
    "model = resnet34(pretrained=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "from shutil import copyfile\n",
    "dog_flag = True\n",
    "\n",
    "imagenet_folders = glob.glob('/home/dexter/Downloads/train/*')\n",
    "if dog_flag:\n",
    "    dataset_path = DOG_DATASET_TRAIN_INTERVAL\n",
    "else:\n",
    "    dataset_path = NAT_DATASET_TRAIN_INTERVAL\n",
    "make_dir(dataset_path)\n",
    "correct = 0\n",
    "wrong = 0\n",
    "indomain_wrong = 0\n",
    "for i, imagenet_folder in enumerate(imagenet_folders):\n",
    "    print(i)\n",
    "    imagenet_id = imagenet_folder.split('train/')[1]\n",
    "\n",
    "    if dog_flag:\n",
    "        if imagenet_id not in dogs_id:\n",
    "            continue\n",
    "\n",
    "    image_paths = glob.glob(imagenet_folder + '/*.*')\n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        if idx == 50:\n",
    "            break\n",
    "        img = Image.open(image_path)\n",
    "        if img.mode != 'RGB' or img.size[0] < 224 or img.size[1] < 224:\n",
    "            continue\n",
    "        x = transform(img).unsqueeze(0).to(device)\n",
    "        out = model(x)\n",
    "        p = torch.nn.functional.softmax(out, dim=1)\n",
    "        score, index = torch.topk(p, 1)\n",
    "        confidence_score = score[0][0].item()\n",
    "        predicted_confidence = (\"%.2f\") %(confidence_score)\n",
    "        category_id = int(index[0][0].item())\n",
    "        prediction_id = convert_imagenet_label_to_id(label_map, key_list, val_list, category_id)\n",
    "\n",
    "        conf_interval = str(int(confidence_score*10))\n",
    "        if int(confidence_score*10) == 10:\n",
    "            conf_interval = str(9)\n",
    "        if prediction_id == imagenet_id:\n",
    "            correct +=1\n",
    "            if os.path.isdir(dataset_path + 'correct_' + conf_interval + '/') == False:\n",
    "                os.mkdir(dataset_path + 'correct_' + conf_interval + '/')\n",
    "            dst_file = dataset_path + 'correct_' + conf_interval + '/' + prediction_id + '_' + image_path.split(imagenet_id + '/')[1].split('.JPEG')[0] + '_' + imagenet_id + '.jpeg'\n",
    "        else:\n",
    "            wrong +=1\n",
    "            # Ensure the prediction is in dog ids\n",
    "            if dog_flag:\n",
    "                if prediction_id not in dogs_id:\n",
    "                    continue\n",
    "                else:\n",
    "                    indomain_wrong += 1\n",
    "            if os.path.isdir(dataset_path + 'wrong_' + conf_interval + '/') == False:\n",
    "                os.mkdir(dataset_path + 'wrong_' + conf_interval + '/')\n",
    "            dst_file = dataset_path + 'wrong_' + conf_interval + '/' + prediction_id + '_' + image_path.split(imagenet_id + '/')[1].split('.JPEG')[0] + '_' + imagenet_id + '.jpeg'\n",
    "        copyfile(image_path, dst_file)\n",
    "\n",
    "\n",
    "print([correct, wrong])\n",
    "print(indomain_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Confidence explanations\n",
    "import cv2 as cv\n",
    "method = 'Conf'\n",
    "# test_image_paths = corrects_bin1[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "#                     wrongs_bin1[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "#                     corrects_bin2[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "#                     wrongs_bin2[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "#                     corrects_bin3[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "#                     wrongs_bin3[methods.index(method)*img_num:methods.index(method)*img_num + img_num]\n",
    "# test_image_paths = ['/home/dexter/Downloads/Dataset/Interval_train_nat/correct_0/n03250847_n03250847_8348_n03250847.jpeg']\n",
    "\n",
    "test_image_paths = glob.glob('/home/dexter/Downloads/Human_experiments/Training/*.*')\n",
    "# Tracer()()\n",
    "# for idx, image_path in enumerate(test_image_paths[methods.index(method)*img_num:methods.index(method)*img_num + img_num]):\n",
    "for idx, image_path in enumerate(test_image_paths):\n",
    "    print(idx + 1)\n",
    "    distance_dict = dict()\n",
    "    neighbors = list()\n",
    "    categories_confidences = list()\n",
    "    confidences= list ()\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    input_image = img.resize((size,size), Image.ANTIALIAS)\n",
    "    image_name = (image_path.split('.jpeg')[0]).split('Training/')[1]\n",
    "    print(image_name)\n",
    "\n",
    "    # Get the ground truth of the input image\n",
    "    gt_label_id = image_path[-14:-5]\n",
    "    \n",
    "    gt_label = id_map.get(gt_label_id)\n",
    "    id = key_list.index(gt_label_id)\n",
    "    gt_label = gt_label.split(',')[0]\n",
    "\n",
    "\n",
    "\n",
    "    # Get the prediction for the input image\n",
    "    img = Image.open(image_path)\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    out = model(x)\n",
    "    p = torch.nn.functional.softmax(out, dim=1)\n",
    "    score, index = torch.topk(p, 1)\n",
    "    input_category_id = index[0][0].item()\n",
    "    predicted_confidence = score[0][0].item()\n",
    "    predicted_confidence = (\"%.2f\") %(predicted_confidence)\n",
    "#     print(predicted_confidence)\n",
    "\n",
    "\n",
    "    input_prediction_id = convert_imagenet_label_to_id(label_map, key_list, val_list, input_category_id)\n",
    "    predicted_label = id_map.get(input_prediction_id).split(',')[0]\n",
    "    predicted_label = predicted_label[0].lower() + predicted_label[1:]\n",
    "\n",
    "    # Original image\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "    plt.axis('off')\n",
    "    plt.title('{}% {}'.format(int(float(predicted_confidence)*100), predicted_label))\n",
    "    plt.imshow(input_image)\n",
    "#     plt.imshow(modified_img[idx])\n",
    "    plt.savefig('tmp/original.jpeg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    img = cv.resize(cv.imread(image_path,0),((size,size)))\n",
    "    edges = cv.Canny(img,100,200)\n",
    "    edges = edges - 255\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(edges, cmap = 'gray')\n",
    "    plt.savefig('tmp/Edge.jpeg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "#     Confidence score only\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "    plt.axis('off')\n",
    "    plt.title('{}: {}'.format(predicted_label, predicted_confidence))\n",
    "    plt.imshow(input_image)\n",
    "    plt.savefig('/home/dexter/Downloads/Human_experiments/Training/{}/{}.jpeg'.format(method, image_name), bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate GradCAM explanations\n",
    "\n",
    "from torchray.attribution.grad_cam import grad_cam\n",
    "method = 'GradCAM'\n",
    "## Creating colormap\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "uP = cm.get_cmap('Reds', 129)\n",
    "dowN = cm.get_cmap('Blues_r', 128)\n",
    "newcolors = np.vstack((\n",
    "    dowN(np.linspace(0, 1, 128)),\n",
    "    uP(np.linspace(0, 1, 129))\n",
    "))\n",
    "cMap = ListedColormap(newcolors, name='RedBlues')\n",
    "cMap.colors[257 // 2, :] = [1, 1, 1, 1]\n",
    "\n",
    "test_image_paths = glob.glob('/home/dexter/Downloads/Human_experiments/Training/*.*')\n",
    "\n",
    "# for idx, image_path in enumerate(test_image_paths[methods.index(method)*img_num:methods.index(method)*img_num + img_num]):\n",
    "for idx, image_path in enumerate(test_image_paths):\n",
    "    print(idx + 1)\n",
    "    distance_dict = dict()\n",
    "    neighbors = list()\n",
    "    categories_confidences = list()\n",
    "    confidences= list ()\n",
    "    img = Image.open(image_path)\n",
    "#     print(test_image_paths[idx])\n",
    "    input_image = img.resize((size,size), Image.ANTIALIAS)\n",
    "    image_name = (image_path.split('.jpeg')[0]).split('Training/')[1]\n",
    "    print(image_name)\n",
    "\n",
    "    # Get the ground truth of the input image\n",
    "    gt_label_id = image_path[-14:-5]\n",
    "\n",
    "    \n",
    "    gt_label = id_map.get(gt_label_id)\n",
    "    id = key_list.index(gt_label_id)\n",
    "    gt_label = gt_label.split(',')[0]\n",
    "\n",
    "\n",
    "    # Get the prediction for the input image\n",
    "    img = Image.open(image_path)\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    out = model(x)\n",
    "    p = torch.nn.functional.softmax(out, dim=1)\n",
    "    score, index = torch.topk(p, 1)\n",
    "    input_category_id = index[0][0].item()\n",
    "    predicted_confidence = score[0][0].item()\n",
    "    predicted_confidence = (\"%.2f\") %(predicted_confidence)\n",
    "#     print(predicted_confidence)\n",
    "\n",
    "\n",
    "    input_prediction_id = convert_imagenet_label_to_id(label_map, key_list, val_list, input_category_id)\n",
    "    predicted_label = id_map.get(input_prediction_id).split(',')[0]\n",
    "    predicted_label = predicted_label[0].lower() + predicted_label[1:]\n",
    "\n",
    "    # Original image\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "    plt.axis('off')\n",
    "    plt.title('{}% {}'.format(int(float(predicted_confidence)*100), predicted_label))\n",
    "    plt.imshow(input_image)\n",
    "#     plt.imshow(modified_img[idx])\n",
    "    plt.savefig('tmp/original.jpeg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    img = cv.resize(cv.imread(image_path,0),((size,size)))\n",
    "    edges = cv.Canny(img,100,200)\n",
    "    edges = edges - 255\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(edges, cmap = 'gray')\n",
    "    plt.savefig('tmp/Edge.jpeg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "#     GRAD-CAM\n",
    "    saliency = grad_cam(\n",
    "        model, x, input_category_id,\n",
    "        saliency_layer='layer4',\n",
    "        resize=True\n",
    "    )\n",
    "\n",
    "    saliency_path = 'saliency_maps/GradCAM_resnet34/'\n",
    "    saliency *= 1.0/saliency.max()\n",
    "    GradCAM = saliency[0][0].cpu().detach().numpy()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "    plt.axis('off')\n",
    "    plt.title('Explanation')\n",
    "    plt.imshow(GradCAM, cmap=cMap, vmin=0, vmax=1)\n",
    "    plt.colorbar(orientation='vertical')\n",
    "    plt.savefig('tmp/heatmap.jpeg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Get overlay version\n",
    "    myCmd = 'composite -blend 10 Edge.jpeg -gravity SouthWest heatmap.jpeg overlay.jpeg'\n",
    "    os.system(myCmd)\n",
    "\n",
    "    img_path = '/home/dexter/Downloads/Human_experiments/Training/{}/{}.jpeg'.format(method, image_name)\n",
    "    myCmd = 'montage original.jpeg overlay.jpeg -tile 2x1 -geometry +0+0 ' + img_path\n",
    "    print(myCmd)\n",
    "    os.system(myCmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SHAP explanations\n",
    "\n",
    "import shap\n",
    "import json\n",
    "##########################################\n",
    "bg_image_paths = glob.glob('/home/dexter/Downloads/Dataset/bg/*.*')\n",
    "bg_inputs = list(map(lambda x: Image.open(x), bg_image_paths))\n",
    "bg_inputs = [transform(x).unsqueeze(0) for x in bg_inputs]\n",
    "bg_inputs = [i.to(device) for i in bg_inputs]\n",
    "\n",
    "background = torch.cat(bg_inputs[:100])\n",
    "background = background.detach()\n",
    "\n",
    "e = shap.DeepExplainer(model, background)\n",
    "\n",
    "# load the ImageNet class names\n",
    "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "fname = shap.datasets.cache(url)\n",
    "with open(fname) as f:\n",
    "    class_names = json.load(f)\n",
    "\n",
    "method = 'SHAP'\n",
    "# SHAP\n",
    "\n",
    "# for idx, image_path in enumerate(test_image_paths[methods.index(method)*img_num:methods.index(method)*img_num + img_num]):\n",
    "for idx, image_path in enumerate(test_image_paths):\n",
    "    print(idx + 1)\n",
    "    distance_dict = dict()\n",
    "    neighbors = list()\n",
    "    categories_confidences = list()\n",
    "    confidences= list ()\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "#     print(test_image_paths[idx])\n",
    "    input_image = img.resize((size,size), Image.ANTIALIAS)\n",
    "    image_name = (image_path.split('.jpeg')[0]).split('Training/')[1]\n",
    "    print(image_name)\n",
    "\n",
    "    gt_label_id = image_path[-14:-5]\n",
    "\n",
    "    gt_label = id_map.get(gt_label_id)\n",
    "    id = key_list.index(gt_label_id)\n",
    "    gt_label = gt_label.split(',')[0]\n",
    "\n",
    "\n",
    "    # Get the prediction for the input image\n",
    "    img = Image.open(image_path)\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    out = model(x)\n",
    "    p = torch.nn.functional.softmax(out, dim=1)\n",
    "    score, index = torch.topk(p, 1)\n",
    "    input_category_id = index[0][0].item()\n",
    "    predicted_confidence = score[0][0].item()\n",
    "    predicted_confidence = (\"%.2f\") %(predicted_confidence)\n",
    "#     print(predicted_confidence)\n",
    "\n",
    "\n",
    "    input_prediction_id = convert_imagenet_label_to_id(label_map, key_list, val_list, input_category_id)\n",
    "    predicted_label = id_map.get(input_prediction_id).split(',')[0]\n",
    "    predicted_label = predicted_label[0].lower() + predicted_label[1:]\n",
    "\n",
    "    # Original image\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "    plt.axis('off')\n",
    "    plt.title('{}% {}'.format(int(float(predicted_confidence)*100), predicted_label))\n",
    "    plt.imshow(input_image)\n",
    "#     plt.imshow(modified_img[idx])\n",
    "    plt.savefig('tmp/original.jpeg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    img = cv.resize(cv.imread(image_path,0),((size,size)))\n",
    "    edges = cv.Canny(img,100,200)\n",
    "    edges = edges - 255\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(edges, cmap = 'gray')\n",
    "    plt.savefig('tmp/Edge.jpeg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "    test_images = Image.open(image_path)\n",
    "    test_images = [transform(test_images).unsqueeze(0)]\n",
    "    test_images = [i.to(device) for i in test_images]\n",
    "\n",
    "    test_images_t = torch.cat(test_images)\n",
    "    shap_values = e.shap_values(test_images_t, ranked_outputs=1, output_rank_order='max') # 2xranked_outputsx1x3x224x224\n",
    "\n",
    "    square_img = np.sum(shap_values[0][0][0], axis=0)\n",
    "    min_val = square_img.min()\n",
    "    max_val = square_img.max()\n",
    "    if (-1*min_val) > max_val:\n",
    "        max_val = -1.0*min_val\n",
    "\n",
    "    square_img *= 1.0/max_val\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "    plt.axis('off')\n",
    "    plt.title('Explanation')\n",
    "    plt.imshow(square_img, cmap=cMap, vmin=0, vmax=1)\n",
    "\n",
    "    plt.colorbar(orientation='vertical')\n",
    "    plt.savefig('tmp/heatmap.jpeg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Get overlay version\n",
    "    myCmd = 'composite -blend 10 tmp/Edge.jpeg -gravity SouthWest tmp/heatmap.jpeg tmp/overlay.jpeg'\n",
    "    os.system(myCmd)\n",
    "\n",
    "    img_path = '/home/dexter/Downloads/Human_experiments/Training/{}/{}.jpeg'.format(method, image_name)\n",
    "    myCmd = 'montage tmp/original.jpeg tmp/overlay.jpeg -tile 2x1 -geometry +0+0 ' + img_path\n",
    "    os.system(myCmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 3-NN explanations\n",
    "\n",
    "imagenet_train_path = '/home/dexter/Downloads/train'\n",
    "K = 3\n",
    "layer = 4\n",
    "feature_extractor = nn.Sequential(*list(model.children())[:layer-6])\n",
    "method = 'NNs'\n",
    "# NNs\n",
    "\n",
    "test_image_paths = glob.glob('/home/dexter/Downloads/Human_experiments/Training/*.*')\n",
    "\n",
    "# for idx, image_path in enumerate(test_image_paths[methods.index(method)*img_num:methods.index(method)*img_num + img_num]):\n",
    "for idx, image_path in enumerate(test_image_paths):\n",
    "    print(idx + 1)\n",
    "    distance_dict = dict()\n",
    "    neighbors = list()\n",
    "    categories_confidences = list()\n",
    "    confidences= list ()\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    if 1:\n",
    "        embedding = feature_extractor(transform(img).unsqueeze(0).to(device)).flatten(start_dim=1) \n",
    "#     print(test_image_paths[idx])\n",
    "    input_image = img.resize((size,size), Image.ANTIALIAS)\n",
    "    image_name = (image_path.split('.jpeg')[0]).split('Training/')[1]\n",
    "    print(image_name)\n",
    "\n",
    "    # Get the ground truth of the input image\n",
    "    gt_label_id = image_path[-14:-5]\n",
    "\n",
    "    gt_label = id_map.get(gt_label_id)\n",
    "    id = key_list.index(gt_label_id)\n",
    "    gt_label = gt_label.split(',')[0]\n",
    "\n",
    "\n",
    "    # Get the prediction for the input image\n",
    "    img = Image.open(image_path)\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    out = model(x)\n",
    "    p = torch.nn.functional.softmax(out, dim=1)\n",
    "    score, index = torch.topk(p, 1)\n",
    "    input_category_id = index[0][0].item()\n",
    "    predicted_confidence = score[0][0].item()\n",
    "    predicted_confidence = (\"%.2f\") %(predicted_confidence)\n",
    "\n",
    "    input_prediction_id = convert_imagenet_label_to_id(label_map, key_list, val_list, input_category_id)\n",
    "    predicted_label = id_map.get(input_prediction_id).split(',')[0]\n",
    "    predicted_label = predicted_label[0].lower() + predicted_label[1:]\n",
    "\n",
    "    # Original image\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "    plt.axis('off')\n",
    "    plt.title('{}% {}'.format(int(float(predicted_confidence)*100), predicted_label))\n",
    "    plt.imshow(input_image)\n",
    "#     plt.imshow(modified_img[idx])\n",
    "    plt.savefig('tmp/original.jpeg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    img = cv.resize(cv.imread(image_path,0),((size,size)))\n",
    "    edges = cv.Canny(img,100,200)\n",
    "    edges = edges - 255\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(edges, cmap = 'gray')\n",
    "    plt.savefig('tmp/Edge.jpeg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    if 1:\n",
    "        from utils import *\n",
    "        ## Nearest Neighbors\n",
    "\n",
    "        predicted_set_path = os.path.join(imagenet_train_path, input_prediction_id)\n",
    "        predicted_set_img_paths = glob.glob(predicted_set_path + '/*.*')\n",
    "        predicted_set_color_images= list()\n",
    "\n",
    "        embedding = embedding.detach()\n",
    "        embedding.to(device)\n",
    "        # Build search space for nearest neighbors\n",
    "        for i, path in enumerate(predicted_set_img_paths):\n",
    "            img = Image.open(path)\n",
    "            if img.mode != 'RGB':\n",
    "                img.close()\n",
    "                del img\n",
    "                continue\n",
    "\n",
    "            x = transform(img).unsqueeze(0).to(device)\n",
    "            out = model(x)\n",
    "            p = torch.nn.functional.softmax(out, dim=1)\n",
    "            del out\n",
    "            score, index = torch.topk(p, 1)\n",
    "            del p\n",
    "            category_id = index[0][0].item()\n",
    "            del score, index\n",
    "            \n",
    "            # This is to avoid the confusion from crane 134 and crane 517 and to make NNs work :)\n",
    "            if input_category_id != category_id:\n",
    "                continue\n",
    "\n",
    "            f = feature_extractor(x)\n",
    "            feature_vector = f.flatten(start_dim=1).to(device)\n",
    "            feature_vector = feature_vector.detach()\n",
    "\n",
    "            del f\n",
    "            distance_dict[path] = torch.dist(embedding, feature_vector)\n",
    "\n",
    "            del feature_vector \n",
    "            torch.cuda.empty_cache()\n",
    "            img.close()\n",
    "            del img\n",
    "            predicted_set_color_images.append(path)\n",
    "\n",
    "        # Get K most similar images\n",
    "        res = dict(sorted(distance_dict.items(), key = itemgetter(1))[:K]) \n",
    "        print(\"Before...\")\n",
    "        print(res)\n",
    "        while distance_dict[list(res.keys())[0]] < 100:\n",
    "            del distance_dict[list(res.keys())[0]]\n",
    "            res = dict(sorted(distance_dict.items(), key = itemgetter(1))[:K]) \n",
    "        print(\"After...\")\n",
    "        print(res)\n",
    "#         del distance_dict\n",
    "        del embedding\n",
    "\n",
    "        similar_images = list(res.keys())\n",
    "#         print(similar_images)\n",
    "#         print([distance_dict[x] for x in similar_images])\n",
    "\n",
    "        for similar_image in similar_images:\n",
    "            img = Image.open(similar_image)\n",
    "            neighbors.append(img.resize((size,size), Image.ANTIALIAS))\n",
    "            x = transform(img).unsqueeze(0).to(device)\n",
    "            out = model(x)\n",
    "            p = torch.nn.functional.softmax(out, dim=1)\n",
    "            score, index = torch.topk(p, 1) # Get 1 most probable classes\n",
    "            category_id = index[0][0].item()\n",
    "            confidence = score[0][0].item()\n",
    "\n",
    "            label = label_map.get(category_id).split(',')[0].replace(\"\\\"\", \"\")\n",
    "            label = label[0].lower() + label[1:]\n",
    "            print(label + \": %.2f\" %(confidence))\n",
    "\n",
    "            categories_confidences.append((label + \": %.2f\" %(confidence)))\n",
    "            confidences.append(confidence)\n",
    "            img.close()\n",
    "            \n",
    "        img_path = '/home/dexter/Downloads/Human_experiments/Training/{}/{}.jpeg'.format(method, image_name)\n",
    "        print(img_path)\n",
    "\n",
    "        for index, neighbor in enumerate(neighbors):\n",
    "            fig = plt.figure()\n",
    "            plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "            plt.axis('off')\n",
    "            plt.title(' ')\n",
    "            plt.imshow(neighbor)\n",
    "            plt.savefig('tmp/{}.jpeg'.format(index), bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "        myCmd = 'montage tmp/[0-2].jpeg -tile x1 -geometry +0+0 ' + 'tmp/aggregate.jpeg'\n",
    "        os.system(myCmd)\n",
    "\n",
    "        myCmd = 'montage tmp/original.jpeg ' + 'tmp/aggregate.jpeg' + ' -tile 2x -geometry +20+0 ' + img_path\n",
    "        os.system(myCmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate intro images for dog/ImageNet image classification\n",
    "from shutil import copyfile\n",
    "imagenet_folders = glob.glob('/home/dexter/Downloads/train/*')\n",
    "\n",
    "cnt = 0\n",
    "correct = 0\n",
    "wrong = 0\n",
    "cmd = 'montage '\n",
    "SPACE = ' '\n",
    "for idx, imagenet_folder in enumerate(imagenet_folders):\n",
    "    if cnt == 50:\n",
    "        break\n",
    "    imagenet_id = imagenet_folder.split('train/')[1]\n",
    "    if imagenet_id not in dogs_id:\n",
    "        continue\n",
    "    cnt += 1\n",
    "    print(imagenet_id)\n",
    "    image_paths = glob.glob(imagenet_folder + '/*.*')\n",
    "    print(image_paths[0])\n",
    "    predicted_label = id_map[imagenet_id].split(',')[0]\n",
    "    predicted_label = predicted_label[0].lower() + predicted_label[1:]\n",
    "    predicted_label = predicted_label.replace(' ','_')\n",
    "    print(predicted_label)\n",
    "    cmd += SPACE + '-label' + SPACE + predicted_label + SPACE + image_paths[1]\n",
    "    \n",
    "cmd += SPACE + '-tile 10x5 -title \\'120 breeds\\' tmp/dog_image_classification.jpeg'\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample images for dog/ImageNet classes\n",
    "from shutil import copyfile\n",
    "imagenet_folders = glob.glob('/home/dexter/Downloads/train/*')\n",
    "samples_folder = 'dog_sample_images/'\n",
    "SPACE = ' '\n",
    "import cv2\n",
    "\n",
    "for idx, imagenet_folder in enumerate(imagenet_folders):\n",
    "    print(idx)\n",
    "    imagenet_id = imagenet_folder.split('train/')[1]\n",
    "    if imagenet_id not in dogs_id:\n",
    "        continue\n",
    "    image_paths = glob.glob(imagenet_folder + '/*.*')\n",
    "    random_image_paths = random.sample(list(image_paths), 3)\n",
    "    while cv2.imread(random_image_paths[0]).shape[0] < 320 or cv2.imread(random_image_paths[1]).shape[0] < 320 or cv2.imread(random_image_paths[2]).shape[0] < 320 or \\\n",
    "            cv2.imread(random_image_paths[0]).shape[1] < 240 or cv2.imread(random_image_paths[1]).shape[1] < 240 or cv2.imread(random_image_paths[2]).shape[1] < 240:\n",
    "        random_image_paths = random.sample(list(image_paths), 3)\n",
    "        \n",
    "    predicted_label = id_map[imagenet_id].split(',')[0]\n",
    "    predicted_label = predicted_label[0].lower() + predicted_label[1:]\n",
    "    predicted_label = predicted_label.replace(' ','_')\n",
    "    cmd = 'montage -mode concatenate' + SPACE + random_image_paths[0] + SPACE + random_image_paths[1] + SPACE + random_image_paths[2] + \\\n",
    "        SPACE + '-resize 320x240 -pointsize 8 -geometry +2+30' + SPACE + samples_folder + \\\n",
    "        imagenet_id + '.jpeg'\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate visualizations for instructions\n",
    "\n",
    "import cv2 as cv\n",
    "method = 'Conf'\n",
    "# test_image_paths = corrects_bin1[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "#                     wrongs_bin1[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "#                     corrects_bin2[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "#                     wrongs_bin2[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "#                     corrects_bin3[methods.index(method)*img_num:methods.index(method)*img_num + img_num] + \\\n",
    "#                     wrongs_bin3[methods.index(method)*img_num:methods.index(method)*img_num + img_num]\n",
    "# test_image_paths = ['/home/dexter/Downloads/Dataset/Interval_train_nat/correct_0/n03250847_n03250847_8348_n03250847.jpeg']\n",
    "\n",
    "test_image_paths = glob.glob('/home/dexter/Downloads/Human_experiments/Dog/Instructions/Inputs/*.*')\n",
    "\n",
    "# for idx, image_path in enumerate(test_image_paths[methods.index(method)*img_num:methods.index(method)*img_num + img_num]):\n",
    "for idx, image_path in enumerate(test_image_paths):\n",
    "    print(idx + 1)\n",
    "    distance_dict = dict()\n",
    "    neighbors = list()\n",
    "    categories_confidences = list()\n",
    "    confidences= list ()\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    input_image = img.resize((size,size), Image.ANTIALIAS)\n",
    "    image_name = (image_path.split('.jpeg')[0]).split('Inputs/')[1]\n",
    "    print(image_name)\n",
    "\n",
    "    # Get the prediction for the input image\n",
    "    img = Image.open(image_path)\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    out = model(x)\n",
    "    p = torch.nn.functional.softmax(out, dim=1)\n",
    "    score, index = torch.topk(p, 1)\n",
    "    input_category_id = index[0][0].item()\n",
    "    predicted_confidence = score[0][0].item()\n",
    "    predicted_confidence = (\"%.2f\") %(predicted_confidence)\n",
    "\n",
    "\n",
    "    input_prediction_id = convert_imagenet_label_to_id(label_map, key_list, val_list, input_category_id)\n",
    "    predicted_label = id_map.get(input_prediction_id).split(',')[0]\n",
    "    predicted_label = predicted_label[0].lower() + predicted_label[1:]\n",
    "\n",
    "    # Original image\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "    plt.axis('off')\n",
    "    plt.title('{}: {}'.format(predicted_label, predicted_confidence))\n",
    "    plt.imshow(input_image)\n",
    "#     plt.imshow(modified_img[idx])\n",
    "    plt.savefig('tmp/original.jpeg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    img = cv.resize(cv.imread(image_path,0),((size,size)))\n",
    "    edges = cv.Canny(img,100,200)\n",
    "    edges = edges - 255\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(edges, cmap = 'gray')\n",
    "    plt.savefig('tmp/Edge.jpeg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "#     Confidence score only\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(6.0,4.5), dpi=300)\n",
    "    plt.axis('off')\n",
    "    plt.title('{}% {}'.format(int(float(predicted_confidence)*100), predicted_label))\n",
    "    plt.imshow(input_image)\n",
    "    plt.savefig('/home/dexter/Downloads/Human_experiments/Dog/Instructions/{}/{}.jpeg'.format(method, image_name), bbox_inches='tight', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate validation image aggregation for paper writing\n",
    "\n",
    "path = '/home/dexter/Downloads/Human_experiments/Stimuli_Natural/Validation/Inputs/'\n",
    "correct_path = path + 'Yes/'\n",
    "wrong_path = path + 'No/'\n",
    "cmd = 'convert {}/*.jpeg -resize 600x600\\! tmp/yes.jpeg'.format(correct_path)\n",
    "os.system(cmd)\n",
    "cmd = 'convert {}/*.jpeg -resize 600x600\\! tmp/no.jpeg'.format(wrong_path)\n",
    "os.system(cmd)\n",
    "correct_labels = ['goldfish', 'hen', 'ostrich', 'balloon', 'hay']\n",
    "wrong_labels = ['african grey', 'hornbill', 'band aid', 'bannister', 'flute']\n",
    "gt_for_wrong_labels = ['dial telephone', 'banana', 'rule', 'cornet', 'hand blower']\n",
    "\n",
    "for idx, label in enumerate(correct_labels):\n",
    "    cmd = 'convert tmp/yes-{}.jpeg -fill green -pointsize 56 -gravity North -background White -splice 0x64 -annotate +0+4 \"{}\" tmp/yes-{}.jpeg'.format(idx, label, idx)\n",
    "    os.system(cmd)\n",
    "    \n",
    "for idx, label in enumerate(wrong_labels):\n",
    "    cmd = 'convert tmp/no-{}.jpeg -fill red -pointsize 56 -gravity North -background White -splice 0x64 -annotate +0+4 \"{}\" tmp/no-{}.jpeg'.format(idx, label, idx)\n",
    "    os.system(cmd)\n",
    "    \n",
    "    cmd = 'convert tmp/no-{}.jpeg -fill green -pointsize 56 -gravity North -background White -splice 0x64 -annotate +0+4 \"{}\" tmp/no-{}.jpeg'.format(idx, gt_for_wrong_labels[idx], idx)\n",
    "    os.system(cmd)\n",
    "cmd = 'montage tmp/yes-[0-4].jpeg tmp/no-[0-4].jpeg -tile 5x2 -geometry 448x448+10+10 tmp/nat.jpeg'\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate validation image aggregation for paper writing\n",
    "\n",
    "path = '/home/dexter/Downloads/Human_experiments/Stimuli_Dog/Validation/Inputs/'\n",
    "correct_path = path + 'Yes/'\n",
    "wrong_path = path + 'No/'\n",
    "cmd = 'convert {}/*.jpeg -resize 600x600\\! tmp/yes.jpeg'.format(correct_path)\n",
    "os.system(cmd)\n",
    "cmd = 'convert {}/*.jpeg -resize 600x600\\! tmp/no.jpeg'.format(wrong_path)\n",
    "os.system(cmd)\n",
    "correct_labels = ['japanese spaniel', 'rhodesian ridgeback', 'basset', 'irish wolfhound', 'african hunting dog']\n",
    "wrong_labels = ['toy terrier', 'walker hound', 'italian greyhound', 'saluki', 'west highland white terrier']\n",
    "gt_for_wrong_labels = ['welsh springer spaniel', 'basset', 'french bulldog', 'cardigan', 'siberian husky']\n",
    "\n",
    "for idx, label in enumerate(correct_labels):\n",
    "    cmd = 'convert tmp/yes-{}.jpeg -fill green -pointsize 56 -gravity North -background White -splice 0x64 -annotate +0+4 \"{}\" tmp/yes-{}.jpeg'.format(idx, label, idx)\n",
    "    os.system(cmd)\n",
    "    \n",
    "for idx, label in enumerate(wrong_labels):\n",
    "    cmd = 'convert tmp/no-{}.jpeg -fill red -pointsize 56 -gravity North -background White -splice 0x64 -annotate +0+4 \"{}\" tmp/no-{}.jpeg'.format(idx, label, idx)\n",
    "    os.system(cmd)\n",
    "    \n",
    "    cmd = 'convert tmp/no-{}.jpeg -fill green -pointsize 56 -gravity North -background White -splice 0x64 -annotate +0+4 \"{}\" tmp/no-{}.jpeg'.format(idx, gt_for_wrong_labels[idx], idx)\n",
    "    os.system(cmd)\n",
    "cmd = 'montage tmp/yes-[0-4].jpeg tmp/no-[0-4].jpeg -tile 5x2 -geometry 448x448+10+10 tmp/dog.jpeg'\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MIND samples\n",
    "imgs = ['/home/dexter/Downloads/Dataset/Dog_wrong_resnet34/ILSVRC2012_val_00013611_n02099601.jpeg',\n",
    "        '/home/dexter/Downloads/Dataset/Dog_wrong_resnet34/ILSVRC2012_val_00024756_n02097298.jpeg',\n",
    "        '/home/dexter/Downloads/Dataset/Dog_wrong_resnet34/ILSVRC2012_val_00005351_n02106550.jpeg',\n",
    "        '/home/dexter/Downloads/Dataset/Dog_wrong_resnet34/ILSVRC2012_val_00001137_n02091244.jpeg']\n",
    "        \n",
    "wrong_labels = ['soccer ball', 'teddy', 'tennis ball', 'punching bag']\n",
    "gt_for_wrong_labels = ['golden retriever', 'scotch terrier', 'rottweiler', 'ibizan hound']\n",
    "\n",
    "for idx, img in enumerate(imgs):\n",
    "    cmd = 'convert {} -resize 600x600\\! tmp/mind.jpeg'.format(img)\n",
    "    os.system(cmd)\n",
    "\n",
    "    cmd = 'convert  tmp/mind.jpeg -fill red -pointsize 28 -gravity North -background White -splice 0x32 -annotate +0+4 \"{}\" mind.jpeg'.format(wrong_labels[idx])\n",
    "    os.system(cmd)\n",
    "\n",
    "    cmd = 'convert  tmp/mind.jpeg -fill green -pointsize 28 -gravity North -background White -splice 0x32 -annotate +0+4 \"{}\" {}.jpeg'.format(gt_for_wrong_labels[idx], idx)\n",
    "    os.system(cmd)\n",
    "    \n",
    "# cmd = 'montage [0-4].jpeg -tile 4x1 -geometry 448x448+10+10 minds.jpeg'\n",
    "# os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class samples\n",
    "imgs = ['n02085620.jpeg',\n",
    "        'n02130308.jpeg',\n",
    "        'n03786901.jpeg',\n",
    "        'n04591157.jpeg',\n",
    "        'n07747607.jpeg']\n",
    "        \n",
    "labels = ['chihuahua', 'cheetah', 'mortar', 'windsor tie', 'orange']\n",
    "definitions = ['an old breed of tiny short-haired dog with protruding eyes from Mexico held to antedate Aztec civilization',\n",
    "               'long-legged spotted cat of Africa and southwestern Asia having nonretractile claws',\n",
    "               'a bowl-shaped vessel in which substances can be ground and mixed with a pestle',\n",
    "               'a wide necktie worn in a loose bow',\n",
    "               'round yellow to orange fruit of any of several citrus trees']\n",
    "               \n",
    "\n",
    "for idx, img in enumerate(imgs):\n",
    "    cmd = 'convert sample_images/{} -resize 1400x600\\! tmp/sample.jpeg'.format(img)\n",
    "    os.system(cmd)\n",
    "\n",
    "    cmd = 'convert  -font Times-New-Roman tmp/sample.jpeg -pointsize 24 -gravity North -background White -splice 0x32 -annotate +0+4 \"{}: {}\" {}'.format(labels[idx], definitions[idx], imgs[idx])\n",
    "    os.system(cmd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize image distribution of ImageNEt and Dogs\n",
    "exp = 'ImageNet'\n",
    "conf_int = [0,1,2,3,4,5,6,7,8,9]\n",
    "imagenet_img_num = [199, 1250, 2171, 2641, 3049, 3599, 3412, 3627, 4748, 23507]\n",
    "dog_img_num = [3, 57, 136, 232, 409, 507, 514, 526, 736, 2690]\n",
    "img_num_percent = []\n",
    "if exp == 'Stanford Dogs':\n",
    "    img_num = dog_img_num\n",
    "else:\n",
    "    img_num = imagenet_img_num\n",
    "for value in img_num:\n",
    "    img_num_percent.append(value/sum(img_num))\n",
    "\n",
    "ax = plt.figure().gca()\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.bar(conf_int, img_num, width=1, align='edge', color='b', ec='black')\n",
    "\n",
    "for index, value in enumerate(img_num):\n",
    "    plt.annotate(str(value), xy=(index, value), ha='left', va='bottom')\n",
    "plt.title('{} image distribution by confidence intervals'.format(exp))\n",
    "plt.ylabel('Numb. of images')\n",
    "plt.xlabel('Confidence')\n",
    "plt.savefig('tmp/{}.jpeg'.format(exp), dpi=300, format='jpeg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "labels = ['ImageNet', 'Stanford Dogs']\n",
    "# ImageNet = [16.67, 16.67, 16.66, 16.67, 16.67, 16.66]\n",
    "# Stanford_Dogs = [16.67, 16.67, 16.66, 16.67, 16.67, 16.66]\n",
    "easy_correct = [16.67, 16.67]\n",
    "medium_correct = [16.67, 16.67]\n",
    "hard_correct = [16.66, 16.66]\n",
    "easy_wrong = [16.67, 16.67]\n",
    "medium_wrong = [16.67, 16.67]\n",
    "hard_wrong = [16.66, 16.66]\n",
    "width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(labels, easy_correct, width, label='Easy Correct')\n",
    "ax.bar(labels, medium_correct, width, bottom=medium_correct, label='Medium Correct')\n",
    "ax.bar(labels, hard_correct, width, bottom=hard_correct, label='Hard Correct')\n",
    "\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_title('Experiments')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Easy Correct': [16.67, 16.67, 16.67],\n",
    "    'Medium Correct': [16.67, 16.67, 16.67],\n",
    "    'Hard Correct': [16.66, 16.67, 16.67],\n",
    "    'Easy Wrong': [16.67, 16.67, 16.67],\n",
    "    'Medium Wrong': [16.67, 16.67, 16.67],\n",
    "    'Hard Wrong': [16.66, 16.67, 16.67]})\n",
    "\n",
    "# Save the chart that's drawn\n",
    "ax = df.plot(stacked=True, kind='barh', figsize=(10, 5))\n",
    "\n",
    "# .patches is everything inside of the chart, lines and\n",
    "# rectangles and circles and stuff. In this case we only\n",
    "# have rectangles!\n",
    "for rect in ax.patches:\n",
    "    # Find where everything is located\n",
    "    height = rect.get_height()\n",
    "    width = rect.get_width()\n",
    "    x = rect.get_x()\n",
    "    y = rect.get_y()\n",
    "    \n",
    "    # The width of the bar is also not pixels, it's the\n",
    "    # number of animals. So we can use it as the label!\n",
    "    label_text = width\n",
    "    \n",
    "    # ax.text(x, y, text)\n",
    "    label_x = x + width / 2\n",
    "    label_y = y + height / 2\n",
    "    print(label_text)\n",
    "    \n",
    "    ax.text(label_x, label_y, label_text, ha='center', va='center')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# font = {'family' : 'serif',\n",
    "#         'weight' : 'bold',\n",
    "#         'size'   : 12}\n",
    "\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "category_names = ['Easy Correct', 'Medium Correct', 'Hard Correct', 'Easy Wrong', 'Medium Wrong', 'Hard Wrong']\n",
    "\n",
    "# results = {\n",
    "#     'Question 1': [10, 15, 17, 32, 26],\n",
    "#     'Question 2': [26, 22, 29, 10, 13],\n",
    "#     'Question 3': [35, 37, 7, 2, 19],\n",
    "#     'Question 4': [32, 11, 9, 15, 33],\n",
    "#     'Question 5': [21, 29, 5, 5, 40],\n",
    "#     'Question 6': [8, 19, 5, 30, 38]\n",
    "# }\n",
    "\n",
    "results = {\n",
    "    'Controlled ImageNet': [16.67, 16.67, 16.66, 16.67, 16.67, 16.66],\n",
    "    'Controlled Stanford Dogs': [16.67, 16.67, 16.66, 16.67, 16.67, 16.66],\n",
    "    'Original ImageNet': [67.77, 7.91, 1.97, 7.42, 9.35, 5.53],\n",
    "    'Original Stanford Dogs': [70.93, 10.45, 1.12, 3.20, 9.74, 4.56],\n",
    "}\n",
    "\n",
    "def survey(results, category_names):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    results : dict\n",
    "        A mapping from question labels to a list of answers per category.\n",
    "        It is assumed all lists contain the same number of entries and that\n",
    "        it matches the length of *category_names*.\n",
    "    category_names : list of str\n",
    "        The category labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    labels = list(results.keys())\n",
    "    data = np.array(list(results.values()))\n",
    "    data_cum = data.cumsum(axis=1)\n",
    "    category_colors = plt.get_cmap('tab10')(\n",
    "        np.linspace(0.15, 0.85, data.shape[1]))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(24, 12))\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.set_xlim(0, np.sum(data, axis=1).max())\n",
    "\n",
    "    for i, (colname, color) in enumerate(zip(category_names, category_colors)):\n",
    "        widths = data[:, i]\n",
    "        starts = data_cum[:, i] - widths\n",
    "        ax.barh(labels, widths, left=starts, height=0.8,\n",
    "                label=colname, color=color)\n",
    "        print(colname)\n",
    "        print(labels)\n",
    "        xcenters = starts + widths / 2\n",
    "        \n",
    "        for tick in ax.get_yticklabels():\n",
    "            tick.set_fontsize('x-large')\n",
    "\n",
    "        r, g, b, _ = color\n",
    "        text_color = 'white' if r * g * b < 0.5 else 'darkgrey'\n",
    "        for y, (x, c) in enumerate(zip(xcenters, widths)):\n",
    "            ax.text(x, y, str((c)), ha='center', va='center',\n",
    "                    color=text_color, fontsize='12', weight='bold', family='serif')\n",
    "#                     color=text_color, fontsize='medium')\n",
    "            ax.legend()\n",
    "    ax.legend(ncol=len(category_names), bbox_to_anchor=(0, 1),\n",
    "              loc='lower left', fontsize='x-large')\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "survey(results, category_names)\n",
    "plt.savefig('tmp/distribution_plot1.jpeg',dpi=400, format='jpeg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing the matplotlib library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt# Declaring the figure or the plot (y, x) or (width, height)\n",
    "import matplotlib\n",
    "\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "# matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "\n",
    "plt.figure(figsize=[20, 10])# Data to be plotted\n",
    "Natural_ImageNet_acc = [80.79, 84.79, 88.77, 87.97, 86.95, 88.23]\n",
    "Natural_Dogs_acc = [81.14, 76.45, 79.78, 76.03, 75.05, 82.88]\n",
    "Adversarial_ImageNet_acc = [0.0, 71.00, 69.93, 74.77, 71.68, 75.07]\n",
    "Adversarial_Dogs_acc = [0.0, 68.36, 64.77, 58.58, 67.19, 58.17]\n",
    "\n",
    "Autonomous_AI = [Natural_ImageNet_acc[0], Natural_Dogs_acc[0], Adversarial_ImageNet_acc[0], Adversarial_Dogs_acc[0]]\n",
    "Confidence = [Natural_ImageNet_acc[1], Natural_Dogs_acc[1], Adversarial_ImageNet_acc[1], Adversarial_Dogs_acc[1]]\n",
    "GradCAM = [Natural_ImageNet_acc[2], Natural_Dogs_acc[2], Adversarial_ImageNet_acc[2], Adversarial_Dogs_acc[2]]\n",
    "EP = [Natural_ImageNet_acc[3], Natural_Dogs_acc[3], Adversarial_ImageNet_acc[3], Adversarial_Dogs_acc[3]]\n",
    "SOD = [Natural_ImageNet_acc[4], Natural_Dogs_acc[4], Adversarial_ImageNet_acc[4], Adversarial_Dogs_acc[4]]\n",
    "NNs = [Natural_ImageNet_acc[5], Natural_Dogs_acc[5], Adversarial_ImageNet_acc[5], Adversarial_Dogs_acc[5]]\n",
    "\n",
    "X = np.arange(len(Autonomous_AI))# Passing the parameters to the bar function, this is the main function which creates the bar plot\n",
    "# Using X now to align the bars side by side\n",
    "\n",
    "\n",
    "plt.bar(X, Autonomous_AI, color = 'blue', width = 0.15)\n",
    "plt.bar(X + 0.15, Confidence, color = 'orange', width = 0.15)\n",
    "plt.bar(X + 0.30, GradCAM, color = 'forestgreen', width = 0.15)\n",
    "plt.bar(X + 0.45, EP, color = 'skyblue', width = 0.15)\n",
    "plt.bar(X + 0.60, SOD, color = 'darkviolet', width = 0.15)\n",
    "plt.bar(X + 0.75, NNs, color = 'firebrick', width = 0.15)\n",
    "\n",
    "for i in range(len(Autonomous_AI)):\n",
    "    plt.annotate(Autonomous_AI[i], (-0.075 + i, Autonomous_AI[i]), va='bottom')\n",
    "    plt.annotate(Confidence[i], (-0.075 + i + 0.15, Confidence[i]), va='bottom')\n",
    "    plt.annotate(GradCAM[i], (-0.075 + i + 0.30, GradCAM[i]), va='bottom')\n",
    "    plt.annotate(EP[i], (-0.075 + i + 0.45, EP[i]), va='bottom')\n",
    "    plt.annotate(SOD[i], (-0.075 + i + 0.60, SOD[i]), va='bottom')\n",
    "    plt.annotate(NNs[i], (-0.075 + i + 0.75, NNs[i]), va='bottom')\n",
    "\n",
    "# plt.legend(['Natural ImageNet', 'Natural Stanford Dogs', 'Adversarial ImageNet', 'Adversarial Stanford Dogs'])# Overiding the x axis with the country names\n",
    "# plt.xticks([i + 0.3 for i in range(6)], ['Autonomous AI', 'Confidence', 'GradCAM', 'EP', 'SOD', '3-NNs'])# Giving the tilte for the plot\n",
    "\n",
    "plt.legend(['AI only', 'Confidence', 'GradCAM', 'EP', 'SOD', '3-NNs'])# Overiding the x axis with the country names\n",
    "plt.xticks([i + 0.375 for i in range(4)], ['Natural ImageNet', 'Natural Stanford Dogs', 'Adversarial ImageNet', 'Adversarial Stanford Dogs'])# Giving the tilte for the plot\n",
    "\n",
    "# plt.style.use('default')\n",
    "# plt.rcParams['text.usetex'] = True\n",
    "\n",
    "# plt.title(\"Human accuracy\")# Namimg the x and y axis\n",
    "plt.xlabel('Experiments', fontsize=14, weight='bold')\n",
    "plt.ylabel('Accuracy (Acc/%)', fontsize=14, weight='bold')# \n",
    "plt.savefig('tmp/accuracy_random.jpeg',dpi=600, format='jpeg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# dang annotate cac bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
